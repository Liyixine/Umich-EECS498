### [ğŸ“š] è§†é¢‘å­¦ä¹ è„šæ‰‹æ¶: EECS 498-007 / 598-005 Deep Learning for Computer Vision - Lecture 1: Introduction

### ä¸€ã€æ ¸å¿ƒå†…å®¹å¤§çº² (Core Content Outline)
-   **è¯¾ç¨‹ä»‹ç» (Course Introduction)**
    -   è¯¾ç¨‹åç§° (Course Name): EECS 498-007 / 598-005 æ·±åº¦å­¦ä¹ ç”¨äºè®¡ç®—æœºè§†è§‰ (Deep Learning for Computer Vision)
    -   æœ¬è®²ä¸»é¢˜ (Lecture Topic): ä»‹ç» (Introduction)
    -   è¯¾ç¨‹æ€§è´¨ (Course Nature): ç‰¹æ®Šä¸“é¢˜è¯¾ç¨‹ï¼Œé¦–æ¬¡åœ¨å¯†æ­‡æ ¹å¤§å­¦å¼€è®¾ (Special topics class, first time taught at Michigan).
-   **è®¡ç®—æœºè§†è§‰ (Computer Vision) å®šä¹‰ä¸é‡è¦æ€§**
    -   å®šä¹‰ (Definition): æ„å»ºèƒ½å¤Ÿå¤„ç† (process)ã€æ„ŸçŸ¥ (perceive) å’Œæ¨ç† (reason) è§†è§‰æ•°æ® (visual data) çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ (artificial systems).
        -   â€œå¤„ç† (process)â€ã€â€œæ„ŸçŸ¥ (perceive)â€ã€â€œæ¨ç† (reason)â€å«ä¹‰å®½æ³› (broad definitions).
        -   è§†è§‰æ•°æ®ç¤ºä¾‹ (Examples of visual data): å›¾åƒ (images)ã€è§†é¢‘ (videos)ã€åŒ»å­¦æ‰«æ (medical scans) ç­‰ä»»ä½•è¿ç»­å€¼ä¿¡å· (continuously valued signals).
    -   é‡è¦æ€§ (Importance): è®¡ç®—æœºè§†è§‰æ— å¤„ä¸åœ¨ (Computer Vision is everywhere).
        -   æ•°æ®é‡å·¨å¤§ (Massive amount of data):
            -   Instagram: æ¯å¤©ä¸Šä¼ çº¦ 1 äº¿å¼ ç…§ç‰‡å’Œè§†é¢‘ (100 million photos/videos uploaded daily).
            -   YouTube (æˆªè‡³ 2015 å¹´): æ¯åˆ†é’Ÿä¸Šä¼ çº¦ 300 å°æ—¶è§†é¢‘ (300 hours of video uploaded every minute).
        -   äººç±»æ— æ³•å¤„ç†å¦‚æ­¤æµ·é‡æ•°æ® (Human manpower cannot process this data).
        -   æœªæ¥é‡è¦æ€§æ—¥ç›Šå¢åŠ  (Increasing future importance): è‡ªåŠ¨é©¾é©¶æ±½è½¦ (autonomous vehicles)ã€å¢å¼º/è™šæ‹Ÿç°å® (augmented/virtual reality)ã€æ— äººæœº (drones) ç­‰æ–°å…´æŠ€æœ¯ (emerging technologies).
    -   è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒé—®é¢˜ (Core Problem of Computer Vision): ç†è§£è§†è§‰æ•°æ® (understanding visual data)ï¼Œä¸å…³å¿ƒå¦‚ä½•å®ç° (doesn't care *how* it's solved).
-   **æ·±åº¦å­¦ä¹  (Deep Learning) å®šä¹‰ä¸å®šä½**
    -   å­¦ä¹  (Learning) çš„å®šä¹‰ (Definition of Learning): æ„å»ºèƒ½å¤Ÿä»æ•°æ® (data) å’Œç»éªŒ (experience) ä¸­å­¦ä¹ çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ (artificial systems that learn from data and experience).
    -   æ·±åº¦å­¦ä¹  (Deep Learning) ä½œä¸ºæŠ€æœ¯:
        -   ç›®å‰è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸»è¦ä½¿ç”¨æ·±åº¦å­¦ä¹  (Deep Learning is the prevailing technique in Computer Vision).
        -   æ·±åº¦å­¦ä¹ æ˜¯åˆ†å±‚å­¦ä¹ ç®—æ³• (Hierarchical learning algorithms)ï¼Œå…·æœ‰å¤šå±‚ (many "layers")ï¼Œæ¾æ•£åœ°å—å¤§è„‘å¯å‘ (loosely inspired by the brain)ã€‚ä½†åº”è°¨æ…çœ‹å¾…ä¸å¤§è„‘çš„ç±»æ¯” (take brain comparisons with a grain of salt).
    -   **äººå·¥æ™ºèƒ½ (Artificial Intelligence)ã€æœºå™¨å­¦ä¹  (Machine Learning)ã€è®¡ç®—æœºè§†è§‰ (Computer Vision) å’Œæ·±åº¦å­¦ä¹  (Deep Learning) çš„å…³ç³» (Relationships)**:
        -   äººå·¥æ™ºèƒ½ (AI): æœ€å¹¿æ³›çš„é¢†åŸŸ (broadest field)ï¼Œç›®æ ‡æ˜¯æ„å»ºèƒ½å¤Ÿæ‰§è¡Œäººç±»é€šå¸¸æ‰§è¡Œä»»åŠ¡çš„æ™ºèƒ½æœºå™¨ (build smart machines that do things normally done by people).
        -   æœºå™¨å­¦ä¹  (ML): äººå·¥æ™ºèƒ½çš„å­é¢†åŸŸ (sub-discipline of AI)ï¼Œå…³æ³¨æ•™æœºå™¨å­¦ä¹  (teaching machines to learn).
        -   è®¡ç®—æœºè§†è§‰ (CV): äººå·¥æ™ºèƒ½çš„å­é¢†åŸŸ (sub-discipline of AI)ï¼Œå…³æ³¨æ•™æœºå™¨çœ‹ (teaching machines to see).
        -   æ·±åº¦å­¦ä¹  (DL): æœºå™¨å­¦ä¹ çš„å­é›† (subset of Machine Learning)ï¼Œä¸è®¡ç®—æœºè§†è§‰æœ‰é‡å  (intersects with Computer Vision).
        -   æœ¬è¯¾ç¨‹å…³æ³¨çš„ç„¦ç‚¹ (Focus of this class): è®¡ç®—æœºè§†è§‰ã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„äº¤é›† (intersection of Computer Vision, Machine Learning, and Deep Learning).
        -   AI çš„å…¶ä»–å­é¢†åŸŸ (Other AI sub-areas): è‡ªç„¶è¯­è¨€å¤„ç† (Natural Language Processing)ã€è¯­éŸ³è¯†åˆ« (Speech Recognition)ã€æœºå™¨äººå­¦ (Robotics) ç­‰ã€‚
-   **è®¡ç®—æœºè§†è§‰ä¸æ·±åº¦å­¦ä¹ ç®€å² (Brief History of Computer Vision and Deep Learning)**
    -   **æ—©æœŸè§†è§‰ç ”ç©¶ (Early Vision Research)**
        -   **Hubel å’Œ Wiesel, 1959** (Hubel and Wiesel, 1959):
            -   ç ”ç©¶çŒ«å¤§è„‘çš„è§†è§‰çš®å±‚ (cat's visual cortex) å¦‚ä½•å“åº”è§†è§‰åˆºæ¿€ (visual stimuli)ã€‚
            -   å‘ç°ä¸åŒç±»å‹çš„ç¥ç»å…ƒ (neurons) å¯¹ç‰¹å®šè§†è§‰æ¨¡å¼ (visual patterns) æœ‰å“åº”ã€‚
                -   ç®€å•ç»†èƒ (Simple cells): å“åº”ç‰¹å®šæ–¹å‘å’Œä½ç½®çš„è¾¹ç¼˜ (oriented edges at specific orientation and position).
                -   å¤æ‚ç»†èƒ (Complex cells): å“åº”è¿åŠ¨ (motion) æˆ–ä»»ä½•ä½ç½®çš„å®šå‘è¾¹ç¼˜ (oriented edges anywhere in visual field)ï¼Œå…·æœ‰å¹³ç§»ä¸å˜æ€§ (translation invariance).
                -   è¶…å¤æ‚ç»†èƒ (Hypercomplex cells): å“åº”å¸¦æœ‰ç«¯ç‚¹çš„è¿åŠ¨ (movement with an end point).
            -   å½±å“ (Influence): å¼ºè°ƒäº†é¢å‘è¾¹ç¼˜ (oriented edges) å’Œè§†è§‰ç³»ç»Ÿçš„åˆ†å±‚è¡¨ç¤º (hierarchical representation) çš„é‡è¦æ€§ã€‚1981 å¹´è·è¯ºè´å°”å¥– (Nobel Prize in 1981).
        -   **Larry Roberts, 1963** (Larry Roberts, 1963):
            -   å¯èƒ½æœ€æ—©çš„è®¡ç®—æœºè§†è§‰åšå£«è®ºæ–‡ (possibly the first PhD thesis on computer vision).
            -   ç³»ç»Ÿèƒ½å¤Ÿä»åŸå§‹å›¾åƒä¸­æ£€æµ‹è¾¹ç¼˜ (detect edges)ï¼Œé€‰æ‹©ç‰¹å¾ç‚¹ (select feature points)ï¼Œå¹¶ç†è§£ç‰©ä½“çš„ä¸‰ç»´å‡ ä½•å½¢çŠ¶ (understand 3D geometry of objects).
            -   æŒ‘æˆ˜ (Challenge): å½“æ—¶å°†å›¾åƒä¿¡æ¯è¾“å…¥è®¡ç®—æœºéå¸¸ç¹ç (cumbersome to get photographic information into computers).
            -   Roberts åæ¥æˆä¸ºäº’è”ç½‘çš„åˆ›å§‹äºº (later became the founding father of the Internet).
        -   **Seymour Papert, 1966** (Seymour Papert, 1966) â€“ æš‘æœŸè§†è§‰é¡¹ç›® (The Summer Vision Project):
            -   MIT çš„ä¸€ä¸ªé›„å¿ƒå‹ƒå‹ƒçš„é¡¹ç›® (ambitious MIT project)ï¼Œæ—¨åœ¨æš‘æœŸå†…æ„å»ºâ€œè§†è§‰ç³»ç»Ÿçš„æ˜¾è‘—éƒ¨åˆ† (significant part of a visual system)â€ã€‚
            -   ç›®æ ‡æœªèƒ½å®ç° (goal not achieved)ï¼Œè¡¨æ˜è®¡ç®—æœºè§†è§‰çš„å¤æ‚æ€§ã€‚
        -   **David Marr, 1970s** (David Marr, 1970s) â€“ è§†è§‰è¡¨å¾é˜¶æ®µ (Stages of Visual Representation):
            -   æå‡ºäº†è§†è§‰å¤„ç†çš„å››ä¸ªé˜¶æ®µ (four stages of visual processing): åŸå§‹å¼ºåº¦ (perceived intensities) -> åŸå§‹è‰å›¾ (primal sketch) -> 2.5D è‰å›¾ (2 1/2-D sketch) -> 3D æ¨¡å‹è¡¨ç¤º (3-D model representation)ã€‚
            -   å†æ¬¡å¼ºè°ƒäº†åˆ†å±‚å¤„ç† (hierarchical processing)ã€‚
        -   **åŸºäºéƒ¨åˆ†è¯†åˆ« (Recognition via Parts, 1970s)**:
            -   å°è¯•å°†ç‰©ä½“åˆ†è§£ä¸ºåŸºæœ¬å‡ ä½•éƒ¨åˆ†è¿›è¡Œè¯†åˆ«ã€‚
            -   æ³›åŒ–åœ†æŸ±ä½“ (Generalized Cylinders, 1979) å’Œå›¾åƒç»“æ„ (Pictorial Structures, 1973)ã€‚
            -   å—é™äºå½“æ—¶è®¡ç®—èƒ½åŠ›å’Œæ•°å­—ç›¸æœºæŠ€æœ¯ (limited by computational power and digital camera technology).
        -   **åŸºäºè¾¹ç¼˜æ£€æµ‹çš„è¯†åˆ« (Recognition via Edge Detection, 1980s)**:
            -   éšç€æ•°å­—ç›¸æœºå’Œè®¡ç®—èƒ½åŠ›çš„è¿›æ­¥ï¼Œç ”ç©¶æ›´çœŸå®å›¾åƒ (more realistic images)ã€‚
            -   John Canny, 1986: Canny è¾¹ç¼˜æ£€æµ‹å™¨ (Canny Edge Detector)ï¼Œä¸€ç§é²æ£’çš„è¾¹ç¼˜æ£€æµ‹ç®—æ³• (robust algorithm for detecting edges).
            -   David Lowe, 1987: é€šè¿‡åŒ¹é…è¾¹ç¼˜è¯†åˆ«ç‰©ä½“ (recognizing objects by matching their edges).
        -   **åŸºäºåˆ†ç»„çš„è¯†åˆ« (Recognition via Grouping, 1990s)**:
            -   ç›®æ ‡æ˜¯å°†å›¾åƒåˆ†å‰²æˆè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„å— (segment image into semantically meaningful chunks)ã€‚
            -   å½’ä¸€åŒ–åˆ‡å‰² (Normalized Cuts, Shi and Malik, 1997) ç®—æ³•ã€‚
        -   **åŸºäºåŒ¹é…çš„è¯†åˆ« (Recognition via Matching, 2000s)**:
            -   SIFT (Scale-Invariant Feature Transform) (David Lowe, 1999): æ£€æµ‹å›¾åƒä¸­çš„å…³é”®ç‚¹ (keypoints)ï¼Œå¹¶è®¡ç®—å¯¹å°ºåº¦ (scale) å’Œæ—‹è½¬ (rotation) ä¸å˜çš„ç‰¹å¾å‘é‡ (feature vectors) æ¥è¡¨ç¤ºå¤–è§‚ (appearance)ã€‚
            -   ç”¨äºåœ¨ä¸åŒå›¾åƒä¸­åŒ¹é…ç‰©ä½“ï¼Œå³ä½¿æœ‰å˜æ¢ (transformations)ã€‚
        -   **äººè„¸æ£€æµ‹ (Face Detection, 2000s)**:
            -   Viola and Jones, 2001: æå‡ºäº†ä¸€ç§å¼ºå¤§çš„äººè„¸æ£€æµ‹ç®—æ³•ã€‚
            -   é‡Œç¨‹ç¢‘ (Milestone): æœºå™¨å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„é¦–æ‰¹æˆåŠŸåº”ç”¨ä¹‹ä¸€ (one of the first successful applications of Machine Learning to Vision)ã€‚
            -   å¿«é€Ÿå•†ä¸šåŒ– (fast commercialization)ï¼Œä¾‹å¦‚æ•°ç ç›¸æœºä¸­çš„è‡ªåŠ¨å¯¹ç„¦ (auto-focus in digital cameras).
        -   **PASCAL è§†è§‰ç‰©ä½“æŒ‘æˆ˜èµ› (PASCAL Visual Object Challenge, 2000s)**:
            -   ä¸€ä¸ªå¤§è§„æ¨¡çš„ç‰©ä½“æ£€æµ‹ä¸è¯†åˆ«åŸºå‡†æŒ‘æˆ˜èµ› (large-scale object detection and recognition benchmark challenge).
            -   æ¨åŠ¨äº†æ€§èƒ½çš„ç¨³æ­¥æå‡ (steady increase in performance).
        -   **ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ› (ImageNet Large Scale Visual Recognition Challenge, 2000s-2010s)**:
            -   ä¸€ä¸ªåŒ…å« 1000 ä¸ªç‰©ä½“ç±»åˆ«ï¼Œ140 å¤šä¸‡å¼ å›¾åƒçš„å·¨å‹æ•°æ®é›† (massive dataset with over 1.4 million images and 1,000 object classes)ã€‚
            -   åˆ›æ–°ç‚¹ (Innovation): åˆ©ç”¨ä¼—åŒ… (crowdsourcing) è¿›è¡Œæ•°æ®æ ‡æ³¨ (data annotation)ã€‚
            -   æŒ‘æˆ˜èµ›æ¯å¹´ä¸¾è¡Œï¼Œè¢«ç§°ä¸ºâ€œè®¡ç®—æœºè§†è§‰ç•Œçš„å¥¥è¿ä¼š (Olympics of Computer Vision)â€ã€‚
            -   2010-2011å¹´é”™è¯¯ç‡åœ¨ 25-28% å·¦å³ (error rates around 25-28%).
            -   **2012 å¹´ï¼šé”™è¯¯ç‡æ˜¾è‘—ä¸‹é™åˆ° 16.4%** (error rate dropped to 16.4%)ï¼Œè¿™æ˜¯â€œè¿›å…¥æ·±åº¦å­¦ä¹  (Enter Deep Learning)â€çš„æ—¶åˆ»ã€‚
            -   æ­¤åé”™è¯¯ç‡æŒç»­å¿«é€Ÿä¸‹é™ï¼Œåˆ° 2017 å¹´ç”šè‡³ä½äºäººç±»çš„è¯†åˆ«é”™è¯¯ç‡ (performance surpassed human error rates).
    -   **æ·±åº¦å­¦ä¹ å†å² (History of Deep Learning)**
        -   **æ„ŸçŸ¥æœº (Perceptron), ~1957** (Frank Rosenblatt):
            -   æœ€æ—©èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ çš„ç®—æ³•ä¹‹ä¸€ (one of the earliest algorithms that could learn from data)ã€‚
            -   ç¡¬ä»¶å®ç° (Implemented in hardware): æƒé‡å­˜å‚¨åœ¨ç”µä½å™¨ (potentiometers) ä¸­ï¼Œå­¦ä¹ æ—¶ç”±ç”µåŠ¨æœº (electric motors) æ›´æ–°ã€‚
            -   èƒ½è¯†åˆ«å­—æ¯ (recognize letters of the alphabet) çš„ 20x20 åƒç´ å›¾åƒã€‚
            -   ç°ä»£è§†è§’ (Modern perspective): è¢«è®¤ä¸ºæ˜¯çº¿æ€§åˆ†ç±»å™¨ (linear classifier)ã€‚
        -   **Minsky å’Œ Papert, 1969** (Minsky and Papert, 1969):
            -   å‡ºç‰ˆäº†åä¸ºã€Šæ„ŸçŸ¥æœºã€‹(Perceptrons) çš„è‘—ä½œã€‚
            -   æŒ‡å‡ºæ„ŸçŸ¥æœºæ— æ³•å­¦ä¹  XOR å‡½æ•° (XOR function) (éçº¿æ€§å¯åˆ†é—®é¢˜)ã€‚
            -   å¯¼è‡´è¯¥é¢†åŸŸå¤§é‡å¹»ç­ (caused a lot of disillusionment)ï¼Œç ”ç©¶åœæ»ï¼Œè¿›å…¥â€œAI å†¬å¤© (AI Winter)â€ã€‚
            -   **å…³é”®ç‚¹ (Key Point)**ï¼šä¹¦ä¸­ä¹Ÿæåˆ°äº†å¤šå±‚æ„ŸçŸ¥æœº (multi-layer perceptrons) å¯ä»¥è§£å†³æ­¤ç±»é—®é¢˜ï¼Œä½†å½“æ—¶è¢«å¿½è§†ã€‚
        -   **æ–°è®¤çŸ¥æœº (Neocognitron): Fukushima, 1980** (Fukushima, 1980):
            -   è®¡ç®—æ¨¡å‹ (computational model) ç›´æ¥å—åˆ° Hubel å’Œ Wiesel çš„å¯å‘ï¼Œå…·æœ‰åˆ†å±‚ç»“æ„ (hierarchical structure) çš„ç®€å•ç»†èƒ (simple cells) å’Œå¤æ‚ç»†èƒ (complex cells)ã€‚
            -   äº¤é”™ä½¿ç”¨ç®€å•ç»†èƒ (å·ç§¯) (simple cells (convolution)) å’Œå¤æ‚ç»†èƒ (æ± åŒ–) (complex cells (pooling))ã€‚
            -   **é—®é¢˜ (Problem)**: æ²¡æœ‰å®ç”¨çš„è®­ç»ƒç®—æ³• (no practical training algorithm)ã€‚
            -   æ•´ä½“æ¶æ„ä¸ 32 å¹´åçš„ AlexNet éå¸¸ç›¸ä¼¼ (overall architecture very similar to AlexNet more than 32 years later)ã€‚
        -   **åå‘ä¼ æ’­ (Backprop): Rumelhart, Hinton, and Williams, 1986** (Rumelhart, Hinton, and Williams, 1986):
            -   å¼•å…¥åå‘ä¼ æ’­ç®—æ³• (backpropagation algorithm)ï¼Œç”¨äºè®¡ç®—ç¥ç»ç½‘ç»œä¸­çš„æ¢¯åº¦ (gradients)ã€‚
            -   é¦–æ¬¡æˆåŠŸè®­ç»ƒå¤šå±‚æ„ŸçŸ¥æœº (successfully trained perceptrons with multiple layers)ï¼Œè§£å†³äº† Minsky å’Œ Papert æå‡ºçš„é—®é¢˜ã€‚
            -   æ˜¯æ·±åº¦å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆè®­ç»ƒçš„å…³é”® (key for efficient training of deep neural networks).
            -   è¯¥ç®—æ³•ä½¿ç”¨äº†ç°ä»£ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„æ¢¯åº¦ (gradients)ã€é›…å¯æ¯”çŸ©é˜µ (Jacobians) å’Œ Hessian çŸ©é˜µ (Hessians) ç­‰æ•°å­¦æœ¯è¯­ (mathematical terminology).
        -   **å·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Networks): LeCun et al, 1998** (LeCun et al, 1998):
            -   å°†åå‘ä¼ æ’­ç®—æ³•åº”ç”¨äºç±»æ–°è®¤çŸ¥æœº (Neocognitron-like) æ¶æ„ (applied backprop algorithm to a Neocognitron-like architecture).
            -   æˆåŠŸè¯†åˆ«æ‰‹å†™æ•°å­— (learned to recognize handwritten digits) (LeNet æ¨¡å‹)ã€‚
            -   å•†ä¸šåº”ç”¨ (Commercial deployment): è¢« NEC å…¬å¸ç”¨äºå¤„ç†æ‰‹å†™æ”¯ç¥¨ (processed handwritten checks)ï¼Œä¸€åº¦å¤„ç†äº†ç¾å›½é«˜è¾¾ 10% çš„æ”¯ç¥¨ (up to 10% of all checks in the United States).
            -   ä¸ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œéå¸¸ç›¸ä¼¼ (very similar to modern convolutional networks).
        -   **2000s: â€œæ·±åº¦å­¦ä¹ â€ (Deep Learning)**:
            -   äººä»¬å°è¯•è®­ç»ƒæ›´æ·± (deeper) çš„ç¥ç»ç½‘ç»œ (neural networks)ã€‚
            -   å½“æ—¶å¹¶éä¸»æµç ”ç©¶æ–¹å‘ (not a mainstream research topic at this time)ã€‚
            -   Hinton å’Œ Salakhutdinov (2006)ã€Bengio et al (2007)ã€Lee et al (2009)ã€Glorot å’Œ Bengio (2010) ç­‰ç ”ç©¶è€…æ¨åŠ¨äº†æ·±åº¦ç½‘ç»œè®­ç»ƒçš„å‘å±•ã€‚
            -   ä¸º 2012 å¹´ AlexNet çš„çªç ´å¥ å®šäº†åŸºç¡€ (laid the groundwork for AlexNet's breakthrough).
-   **2012 å¹´è‡³ä»Šï¼šæ·±åº¦å­¦ä¹ å¤§çˆ†å‘ (Deep Learning Explosion)**
    -   **æ±‡æµ (Confluence)**: 2012 å¹´æ˜¯ç®—æ³• (algorithms)ã€æ•°æ® (data) å’Œè®¡ç®— (computation) ä¸‰å¤§è¦ç´ çš„æ±‡æµç‚¹ (great confluence of algorithms, data, and computation).
        -   **ç®—æ³• (Algorithms)**: ç»è¿‡å¤šå¹´å‘å±•ï¼Œæœ‰äº†å¼ºå¤§çš„å¯å­¦ä¹ å‡½æ•°è¡¨ç¤ºå·¥å…·å’Œåå‘ä¼ æ’­ç­‰è®­ç»ƒæ–¹æ³• (powerful tools for learnable functions and training methods).
        -   **æ•°æ® (Data)**: æ•°å­—ç›¸æœºã€äº’è”ç½‘å’Œä¼—åŒ… (digital cameras, Internet, crowdsourcing) å¸¦æ¥æµ·é‡æ ‡æ³¨æ•°æ® (unprecedented amounts of labeled data)ï¼Œå¦‚ ImageNetã€‚
        -   **è®¡ç®— (Computation)**: GPU (Graphics Processing Units) åœ¨æ€§èƒ½ä¸æˆæœ¬æ•ˆç›Šä¸Šçˆ†å‘å¼å¢é•¿ (exponential growth in GigaFLOPs per dollar for GPUs vs CPUs)ï¼Œè¿œè¶… CPUã€‚ä¾‹å¦‚ï¼ŒGeForce GTX 580 (AlexNet ä½¿ç”¨) å’Œ GTX 1080 Tiã€‚
    -   **å½±å“ (Impact)**: æ·±åº¦å­¦ä¹ åœ¨ Google Trends ä¸Šçš„å…´è¶£åº¦ä»¥åŠåœ¨ CVPR (è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®) ä¸Šçš„è®ºæ–‡æäº¤å’Œæ¥å—æ•°é‡éƒ½å‘ˆæŒ‡æ•°çº§å¢é•¿ (exponential growth in interest and publications).
    -   **åº”ç”¨æ— å¤„ä¸åœ¨ (ConvNets are everywhere)**:
        -   å›¾åƒåˆ†ç±» (Image Classification): ä¸ºå›¾åƒæ‰“æ ‡ç­¾ (putting labels on images).
        -   å›¾åƒæ£€ç´¢ (Image Retrieval): ä»å›¾åƒåº“ä¸­æ£€ç´¢ç›¸ä¼¼å›¾åƒ (retrieving images from collections).
        -   ç‰©ä½“æ£€æµ‹ (Object Detection): è¯†åˆ«å›¾åƒä¸­ç‰©ä½“çš„ä½ç½®å’Œç±»åˆ« (recognizing positions and labels of objects).
        -   è¯­ä¹‰åˆ†å‰² (Image Segmentation - è§†é¢‘ä¸­è®²å¸ˆå£è¯¯è¯´æˆ Image Retrieval): åƒç´ çº§è¯­ä¹‰åˆ†ç»„ (semantic grouping of pixels).
        -   è§†é¢‘åˆ†ç±» (Video Classification): è¯†åˆ«è§†é¢‘ä¸­çš„æ´»åŠ¨ (activity recognition).
        -   å§¿æ€è¯†åˆ« (Pose Recognition): è¯†åˆ«å›¾åƒä¸­äººç‰©çš„ç²¾ç¡®å‡ ä½•å§¿æ€ (estimating geometric poses of people).
        -   ç© Atari æ¸¸æˆ (Playing Atari games): å¤„ç†è§†è§‰è¾“å…¥ (processing visual input) å¹¶å­¦ä¹ ç©æ³• (learning how to play).
        -   åŒ»å­¦å½±åƒ (Medical Imaging): è¯Šæ–­è‚¿ç˜¤ã€çš®è‚¤ç—…å˜ç­‰ (diagnosing tumors, skin lesions, etc.).
        -   æ˜Ÿç³»åˆ†ç±» (Galaxy Classification).
        -   é²¸é±¼è¯†åˆ« (Whale recognition).
        -   å›¾åƒæè¿° (Image Captioning) (åˆ©ç”¨ RNNs): ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿° (generating natural language descriptions).
        -   ç”Ÿæˆè‰ºæœ¯ (Generating art): DeepDreamã€è‰ºæœ¯é£æ ¼è¿ç§» (Artistic Style Transfer) ç­‰ (DeepDream, Artistic Style Transfer).
    -   **è®¡ç®—æœºè§†è§‰çš„æœªæ¥ä¸æŒ‘æˆ˜ (Future and Challenges of Computer Vision)**:
        -   å°½ç®¡å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œè®¡ç®—æœºè§†è§‰ä»æœ‰å¾ˆé•¿çš„è·¯è¦èµ° (Despite our success, computer vision still has a long way to go).
        -   å½“å‰ç³»ç»Ÿæ— æ³•ç†è§£å¤æ‚åœºæ™¯ä¸­çš„ç‰©ç†å’Œç¤¾ä¼šå«ä¹‰ (cannot understand physical and social implications in complex scenes), ä¾‹å¦‚å¥¥å·´é©¬åœ¨ä½“é‡ç§¤ä¸Šä½œå¼Šçš„å›¾ç‰‡ã€‚
        -   æœªæ¥æ½œåŠ›å·¨å¤§ (Huge potential):
            -   ä½¿ç”Ÿæ´»æ›´æœ‰è¶£ (more fun): æ¸¸æˆã€AR/VRã€‚
            -   äº¤é€šæ›´å®‰å…¨ (safer transportation): è‡ªåŠ¨é©¾é©¶ã€‚
            -   æ”¹å–„åŒ»ç–—è¯Šæ–­ (improved medical diagnosis).
            -   ä½œä¸ºé€šç”¨ä¼ æ„Ÿå™¨ (universal sensor) å¸®åŠ©ç§‘å­¦å®¶ç†è§£æ•°æ® (helping scientists understand data).
    -   **2018 å¹´å›¾çµå¥– (2018 Turing Award)**: æˆäºˆ Yoshua Bengio, Geoffrey Hinton, å’Œ Yann LeCunï¼Œè¡¨å½°ä»–ä»¬åœ¨æ·±åº¦å­¦ä¹ æ–¹é¢çš„å¼€åˆ›æ€§å·¥ä½œ (pioneering work in Deep Learning).

### äºŒã€å…³é”®æœ¯è¯­å®šä¹‰ (Key Term Definitions)
-   **ç®€å•ç»†èƒ (Simple cells)**: (Hubel and Wiesel) çŒ«è§†è§‰çš®å±‚ä¸­çš„ç¥ç»å…ƒï¼Œå“åº”ç‰¹å®šæ–¹å‘å’Œä½ç½®çš„è¾¹ç¼˜ (oriented edges at specific orientation and position).
-   **å¤æ‚ç»†èƒ (Complex cells)**: (Hubel and Wiesel) çŒ«è§†è§‰çš®å±‚ä¸­çš„ç¥ç»å…ƒï¼Œå“åº”è¿åŠ¨æˆ–ä»»ä½•ä½ç½®çš„å®šå‘è¾¹ç¼˜ï¼Œå…·æœ‰å¹³ç§»ä¸å˜æ€§ (responds to motion or oriented edges anywhere, with translation invariance).
-   **æ„ŸçŸ¥æœº (Perceptron)**: (Frank Rosenblatt) æœ€æ—©èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ çš„ç®—æ³•ä¹‹ä¸€ï¼Œç¡¬ä»¶å®ç°ï¼Œè¢«è®¤ä¸ºæ˜¯çº¿æ€§åˆ†ç±»å™¨ (one of the earliest algorithms that could learn from data, hardware implementation, considered a linear classifier).
-   **å¤šå±‚æ„ŸçŸ¥æœº (Multi-layer perceptron)**: å…·æœ‰å¤šä¸ªéšè—å±‚ (multiple hidden layers) çš„æ„ŸçŸ¥æœºï¼Œå…·æœ‰æ›´å¼ºçš„å‡½æ•°è¡¨ç¤ºèƒ½åŠ› (more powerful function representation capabilities)ã€‚
-   **AI å†¬å¤© (AI Winter)**: 1969 å¹´ Minsky å’Œ Papert å‡ºç‰ˆã€Šæ„ŸçŸ¥æœºã€‹åï¼Œç”±äºå…¶å±€é™æ€§ï¼Œå¯¼è‡´å¯¹äººå·¥æ™ºèƒ½å’Œç¥ç»ç½‘ç»œç ”ç©¶çš„èµ„åŠ©å’Œå…´è¶£é”å‡çš„æ—¶æœŸ (a period of reduced funding and interest in AI and neural network research following the publication of "Perceptrons").
-   **æ–°è®¤çŸ¥æœº (Neocognitron)**: (Fukushima) è®¡ç®—æ¨¡å‹ï¼Œç›´æ¥å—åˆ° Hubel å’Œ Wiesel å¯å‘ï¼Œå…·æœ‰å·ç§¯ (convolution) å’Œæ± åŒ– (pooling) æ“ä½œçš„äº¤é”™å±‚ï¼Œä½†æ²¡æœ‰å®ç”¨çš„è®­ç»ƒç®—æ³• (computational model inspired by Hubel and Wiesel, with interleaved layers of convolution and pooling, but no practical training algorithm).
-   **åå‘ä¼ æ’­ (Backpropagation)**: (Rumelhart, Hinton, and Williams) ç”¨äºè®¡ç®—ç¥ç»ç½‘ç»œä¸­æ¢¯åº¦çš„ç®—æ³•ï¼Œä½¿å¾—æœ‰æ•ˆè®­ç»ƒå¤šå±‚ç¥ç»ç½‘ç»œæˆä¸ºå¯èƒ½ (algorithm for computing gradients in neural networks, enabling efficient training of multi-layer neural networks). è¯¥ç®—æ³•ä½¿ç”¨äº†æ¢¯åº¦ (gradients)ã€é›…å¯æ¯”çŸ©é˜µ (Jacobians) å’Œ Hessian çŸ©é˜µ (Hessians) ç­‰æ•°å­¦æœ¯è¯­ (mathematical terminology).
-   **å·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Network, CNN)**: (LeCun et al) ä¸€ç§ç‰¹æ®Šç±»å‹çš„ç¥ç»ç½‘ç»œï¼Œæ“…é•¿å¤„ç†å›¾åƒæ•°æ®ï¼Œé€šè¿‡å·ç§¯å’Œæ± åŒ–æ“ä½œè¿›è¡Œç‰¹å¾å­¦ä¹  (a type of neural network specialized for image data, using convolution and pooling for feature learning).
-   **SIFT (Scale-Invariant Feature Transform)**: (David Lowe) ä¸€ç§å›¾åƒç‰¹å¾æå–ç®—æ³•ï¼Œèƒ½å¤Ÿæ£€æµ‹å›¾åƒä¸­çš„å…³é”®ç‚¹ï¼Œå¹¶ç”Ÿæˆå¯¹å°ºåº¦ã€æ—‹è½¬å’Œå…‰ç…§å˜åŒ–å…·æœ‰ä¸å˜æ€§çš„ç‰¹å¾æè¿°ç¬¦ (image feature extraction algorithm detecting keypoints and generating descriptors invariant to scale, rotation, and lighting).
-   **ImageNet**: (Fei-Fei Li et al) ä¸€ä¸ªå¤§è§„æ¨¡å›¾åƒæ•°æ®é›† (large-scale image dataset)ï¼Œç”¨äºè§†è§‰è¯†åˆ«ä»»åŠ¡çš„åŸºå‡†æµ‹è¯• (benchmarking visual recognition tasks)ã€‚
-   **GPU (Graphics Processing Unit)**: å›¾å½¢å¤„ç†å™¨ï¼Œæœ€åˆç”¨äºå›¾å½¢æ¸²æŸ“ï¼Œåå› å…¶å¹¶è¡Œè®¡ç®—èƒ½åŠ›åœ¨æ·±åº¦å­¦ä¹ ä¸­å‘æŒ¥é‡è¦ä½œç”¨ (graphics processor, key for deep learning due to parallel computing).
-   **å›¾çµå¥– (Turing Award)**: è®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„æœ€é«˜è£èª‰ï¼Œè¢«è®¤ä¸ºæ˜¯â€œè®¡ç®—æœºç§‘å­¦çš„è¯ºè´å°”å¥–â€ (highest honor in computer science, considered the "Nobel Prize of computing").

### ä¸‰ã€æ ¸å¿ƒç®—æ³•ä¸ä»£ç ç‰‡æ®µ (Core Algorithms & Code Snippets)
æœ¬æ¬¡è§†é¢‘æœªåŒ…å«è¯¦ç»†çš„ç®—æ³•æ­¥éª¤æˆ–ä»£ç ç¤ºä¾‹ï¼Œä¸»è¦ä¾§é‡äºæ¦‚å¿µä»‹ç»å’Œå†å²æ²¿é©ã€‚è§†è§‰æ¨¡å‹å’Œç®—æ³•é€šè¿‡å›¾ç¤ºå’Œç®€ä»‹çš„æ–¹å¼å‘ˆç°ã€‚

### å››ã€è®²å¸ˆæå‡ºçš„æ€è€ƒé¢˜ (Questions Posed by the Instructor)
-   â€œå¤„ç† (process)â€ã€â€œæ„ŸçŸ¥ (perceive)â€å’Œâ€œæ¨ç† (reason)â€çš„å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ (What does process, perceive, and reason mean?) [0:44]
-   â€œè§†è§‰æ•°æ® (visual data)â€æ„å‘³ç€ä»€ä¹ˆï¼Ÿ (What does visual data mean?) [0:48]
-   æˆ‘ä»¬åº”è¯¥å¦‚ä½•è§£å†³ç†è§£è§†è§‰æ•°æ®çš„é—®é¢˜ï¼Ÿ(How do we solve the problem of understanding visual data?) [3:23]
-   ä»€ä¹ˆæ˜¯å­¦ä¹  (What is learning)? [3:42]
-   ä¸ºä»€ä¹ˆè®¡ç®—æœºè§†è§‰å’Œå­¦ä¹ ä¼šç»“åˆåœ¨ä¸€èµ·ï¼Ÿ(Why do Computer Vision and Learning go together?) [4:08]
-   ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ å’Œå¤§è„‘çš„æ¯”è¾ƒåº”è¯¥è¢«è°¨æ…çœ‹å¾…ï¼Ÿ(Why should comparisons between Deep Learning and the brain be taken with a grain of salt?) [5:01]
-   ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ(What is Artificial Intelligence?) [5:31]
-   è®¡ç®—æœºè§†è§‰æ˜¯å¦æ˜¯å”¯ä¸€çš„äººå·¥æ™ºèƒ½ç±»å‹ï¼Ÿæ·±åº¦å­¦ä¹ æ˜¯å¦æ˜¯å”¯ä¸€çš„äººå·¥æ™ºèƒ½ç±»å‹ï¼Ÿæ·±åº¦å­¦ä¹ æ˜¯å¦æ˜¯å”¯ä¸€çš„è®¡ç®—æœºè§†è§‰ç±»å‹ï¼Ÿ (Is Computer Vision the only type of AI? Is Deep Learning the only type of AI? Is Deep Learning the only type of Computer Vision?) [6:30]
-   åœ¨æ½œå…¥ææ–™ä¹‹å‰ï¼Œå…³äºå†å²æ€§æ¦‚è¿°æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ(Are there any questions about the historical overview before we dive into the material?) [30:00]
-   Minsky å’Œ Papert çš„ä¹¦å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ(What went wrong with Minsky and Papert's book?) [31:24]
-   æ˜¯ä»€ä¹ˆå¯¼è‡´äº† 2012 å¹´çš„æ·±åº¦å­¦ä¹ å¤§çˆ†å‘ï¼Ÿ(What was it that happened in 2012 that made all of this take off?) [39:54]
-   å°½ç®¡å–å¾—äº†æˆåŠŸï¼Œè®¡ç®—æœºè§†è§‰è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°å—ï¼Ÿ(Despite our success, computer vision still has a long way to go?) [43:33]
-   å…³äºå†…å®¹æˆ–æ”¿ç­–ï¼Œæœ‰å“ªäº›é—®é¢˜ï¼Ÿ(Any questions about content, or policies, or late days, or anything like that?) [50:56]
-   è¿™ä¸ªè¯¾ç¨‹çš„ææ–™æ˜¯å¦å¯ä»¥ä¾›ä¸åœ¨ç­‰å¾…åå•ä¸Šçš„äººä½¿ç”¨ï¼Ÿ(Will the course materials be available for people not on the waitlist?) [51:00]
-   åœ¨ç¬¬ä¸€ä¸ªä½œä¸šä¸­å¯ä»¥ä½¿ç”¨ä»»æ„æ•°é‡çš„å»¶è¿Ÿå¤©æ•°å—ï¼Ÿ(Can we use as many late days as we want for the first assignment?) [51:16]
-   å…³äºåˆä½œæ”¿ç­–æœ‰ä»»ä½•é—®é¢˜å—ï¼Ÿ(Any questions about the collaboration policy?) [52:41]