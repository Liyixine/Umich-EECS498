### [ğŸ“š] è§†é¢‘å­¦ä¹ è„šæ‰‹æ¶: Lecture 17: 3D Vision

### ä¸€ã€æ ¸å¿ƒå†…å®¹å¤§çº² (Core Content Outline)
-   **å¼•è¨€ä¸2Dè§†è§‰å›é¡¾ (Introduction & 2D Vision Recap)**
    -   æœ¬è®²ä¸»é¢˜ï¼š3Dè§†è§‰ (3D Vision) [00:00]
    -   å›é¡¾2Då½¢çŠ¶é¢„æµ‹ä»»åŠ¡ (Predicting 2D Shapes of Objects) [00:07]
        -   åˆ†ç±» (Classification): è¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚
        -   è¯­ä¹‰åˆ†å‰² (Semantic Segmentation): ä¸ºå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ åˆ†é…ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚è‰åœ°ã€çŒ«ã€æ ‘ã€å¤©ç©ºï¼‰ã€‚
        -   ç›®æ ‡æ£€æµ‹ (Object Detection): è¯†åˆ«å›¾åƒä¸­çš„å¤šä¸ªå¯¹è±¡å¹¶ç”¨è¾¹ç•Œæ¡†å®šä½ï¼ˆå¦‚ç‹—ã€ç‹—ã€çŒ«ï¼‰ã€‚
        -   å®ä¾‹åˆ†å‰² (Instance Segmentation): è¯†åˆ«å›¾åƒä¸­çš„æ¯ä¸ªå¯¹è±¡å®ä¾‹ï¼Œå¹¶ç»™å‡ºç²¾ç¡®çš„åƒç´ çº§æ©ç ï¼ˆå¦‚ç‹—ã€ç‹—ã€çŒ«ï¼‰ã€‚
        -   å…¶ä»–ä»»åŠ¡ï¼šå…³é”®ç‚¹ä¼°è®¡ (Keypoint Estimation)ã€‚
    -   2Dä»»åŠ¡ç‰¹ç‚¹ï¼šä¸»è¦å…³æ³¨å›¾åƒå†…çš„è¯†åˆ«å’Œå®šä½ï¼Œä¸æ¶‰åŠç©ºé—´æ·±åº¦ä¿¡æ¯ã€‚
    -   å‘3Dè§†è§‰çš„è¿‡æ¸¡ (Transition to 3D Vision) [01:02]
        -   ç°å®ä¸–ç•Œæ˜¯ä¸‰ç»´çš„ (The world we live in is three-dimensional)ã€‚
        -   ç›®æ ‡ï¼šä½¿ç¥ç»ç½‘ç»œæ¨¡å‹èƒ½å¤Ÿå¤„ç†å’Œç†è§£ä¸‰ç»´ç©ºé—´ä¿¡æ¯ (add this third spatial dimension to our neural network models)ã€‚

-   **3Dè§†è§‰çš„ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ (Two Core Problems in 3D Vision)** [01:31]
    -   **é—®é¢˜ä¸€ï¼šä»å•å¼ å›¾åƒé¢„æµ‹3Då½¢çŠ¶ (Predicting 3D Shapes from single image)**
        -   è¾“å…¥ï¼šå•å¼ RGBå›¾åƒ (single RGB image)ã€‚
        -   è¾“å‡ºï¼šå¯¹è±¡çš„ä¸‰ç»´å½¢çŠ¶è¡¨ç¤º (representation of the 3D shape of objects)ã€‚
    -   **é—®é¢˜äºŒï¼šå¤„ç†3Dè¾“å…¥æ•°æ® (Processing 3D input data)**
        -   è¾“å…¥ï¼šä¸‰ç»´æ•°æ® (3D data)ã€‚
        -   è¾“å‡ºï¼šåŸºäºä¸‰ç»´è¾“å…¥çš„åˆ†ç±»æˆ–åˆ†å‰²å†³ç­– (classification decision or some segmentation decision)ã€‚
    -   å‡è®¾ï¼šä»Šæ—¥è®¨è®ºå‡åŸºäºå…¨ç›‘ç£ä»»åŠ¡ (fully supervised task)ï¼Œå³æœ‰å®Œæ•´çš„è®­ç»ƒé›†åŒ…å«è¾“å…¥å’Œå¯¹åº”çš„çœŸå®æ ‡ç­¾ã€‚

-   **3Dè§†è§‰çš„æ›´å¤šä¸»é¢˜ (Many More Topics in 3D Vision)** [03:02]
    -   è®¡ç®—å¯¹åº”å…³ç³» (Computing correspondences)
    -   å¤šè§†è§’ç«‹ä½“ (Multi-view stereo)
    -   è¿åŠ¨ç»“æ„ (Structure from Motion)
    -   åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»º (Simultaneous Localization and Mapping, SLAM)
    -   è‡ªç›‘ç£å­¦ä¹  (Self-supervised learning)
    -   è§†å›¾åˆæˆ (View Synthesis)
    -   å¯å¾®åˆ†å›¾å½¢ (Differentiable graphics)
    -   3Dä¼ æ„Ÿå™¨ (3D Sensors)
    -   æ³¨ï¼š3Dè§†è§‰é¢†åŸŸæœ‰è®¸å¤šéæ·±åº¦å­¦ä¹ æ–¹æ³•ä»ç„¶æ´»è·ƒä¸”é‡è¦ (Many non-Deep Learning methods alive and well in 3D!)ï¼Œå› ä¸ºæ¶‰åŠåˆ°å¤§é‡çš„å‡ ä½•å­¦çŸ¥è¯†ã€‚

-   **3Då½¢çŠ¶è¡¨ç¤º (3D Shape Representations)** [04:57, 31:02]
    -   **æ·±åº¦å›¾ (Depth Map)** [05:37]
        -   å®šä¹‰ï¼šä¸ºæ¯ä¸ªåƒç´ æä¾›ä»ç›¸æœºåˆ°è¯¥åƒç´ å¤„ä¸–ç•Œä¸­å¯¹è±¡çš„è·ç¦» (distance from the camera to the object in the world at that pixel)ã€‚
        -   RGBå›¾åƒ + æ·±åº¦å›¾åƒ = RGB-Då›¾åƒ (2.5D) (RGB image + Depth image = RGB-D Image (2.5D))ã€‚
        -   è·å–æ–¹å¼ï¼šå¯ç›´æ¥é€šè¿‡æŸäº›3Dä¼ æ„Ÿå™¨ï¼ˆå¦‚Microsoft Kinectï¼‰è®°å½•ã€‚
        -   å±€é™æ€§ï¼šæ— æ³•æ•æ‰è¢«é®æŒ¡å¯¹è±¡ (cannot capture occluded objects)ã€‚
        -   **é¢„æµ‹æ·±åº¦å›¾ (Predicting Depth Maps)** [08:09]
            -   æ¶æ„ï¼šå…¨å·ç§¯ç½‘ç»œ (Fully Convolutional network)ã€‚
            -   æŸå¤±å‡½æ•°ï¼šé€åƒç´ L2è·ç¦»æŸå¤± (Per-pixel Loss (L2 Distance))ã€‚
            -   é—®é¢˜ï¼šå°ºåº¦/æ·±åº¦æ¨¡ç³Šæ€§ (Scale / Depth Ambiguity) [09:47]
                -   å®šä¹‰ï¼šå°è€Œè¿‘çš„ç‰©ä½“ä¸å¤§è€Œè¿œçš„ç‰©ä½“åœ¨å•å¼ å›¾åƒä¸­çœ‹èµ·æ¥å®Œå…¨ç›¸åŒ (A small, close object looks exactly the same as a larger, farther-away object)ã€‚ç»å¯¹å°ºåº¦/æ·±åº¦æ˜¯æ¨¡ç³Šçš„ (Absolute scale / depth are ambiguous from a single image)ã€‚
            -   è§£å†³æ–¹æ¡ˆï¼šå°ºåº¦ä¸å˜æŸå¤± (Scale invariant loss) [10:54]
                -   æŸå¤±å‡½æ•°è®¾è®¡ä½¿å…¶ä¸æƒ©ç½šå…¨å±€å°ºåº¦ä¸Šçš„åå·® (does not penalize a global multiplicative offset in scale)ã€‚
    -   **è¡¨é¢æ³•çº¿ (Surface Normals)** [12:10]
        -   å®šä¹‰ï¼šä¸ºæ¯ä¸ªåƒç´ æä¾›ä¸€ä¸ªå‘é‡ï¼Œè¡¨ç¤ºè¯¥åƒç´ å¤„ä¸–ç•Œä¸­å¯¹è±¡çš„æ³•å‘é‡ (a vector giving the normal vector to the object in the world for that pixel)ã€‚
        -   è¡¨ç¤ºï¼šé€šå¸¸ä½¿ç”¨RGBé¢œè‰²æ¥ç»˜åˆ¶æ³•çº¿å›¾ã€‚
        -   **é¢„æµ‹æ³•çº¿ (Predicting Normals)** [13:35]
            -   æ¶æ„ï¼šä¸é¢„æµ‹æ·±åº¦å›¾ç±»ä¼¼çš„å…¨å·ç§¯ç½‘ç»œã€‚
            -   æŸå¤±å‡½æ•°ï¼šé€åƒç´ ç‚¹ç§¯æŸå¤± (Per-pixel Loss: $(x \cdot y) / (|x| |y|)$) (ä½™å¼¦ç›¸ä¼¼åº¦)ã€‚
            -   ä¼˜åŠ¿ï¼šæ¯”æ·±åº¦å›¾æä¾›æ›´å¤šå‡ ä½•ä¿¡æ¯ã€‚
            -   å±€é™æ€§ï¼šä¸æ·±åº¦å›¾ç±»ä¼¼ï¼Œæ— æ³•è¡¨ç¤ºè¢«é®æŒ¡éƒ¨åˆ†ã€‚
            -   å¯è®­ç»ƒè”åˆç½‘ç»œ (joint network) åŒæ—¶è¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡å’Œæ³•çº¿ä¼°è®¡ã€‚
    -   **ä½“ç´ ç½‘æ ¼ (Voxel Grid)** [15:05, 31:02]
        -   å®šä¹‰ï¼šç”¨V x V x Vçš„å ç”¨ç‡ç½‘æ ¼æ¥è¡¨ç¤ºå½¢çŠ¶ (Represent a shape with a V x V x V grid of occupancies)ã€‚ç±»ä¼¼äº3Dçš„åˆ†å‰²æ©ç  (segmentation masks in Mask R-CNN, but in 3D!)ã€‚
        -   ä¼˜åŠ¿ï¼šæ¦‚å¿µä¸Šç®€å• (Conceptually simple: just a 3D grid!)ã€‚
        -   åŠ£åŠ¿ï¼šéœ€è¦é«˜ç©ºé—´åˆ†è¾¨ç‡æ¥æ•æ‰ç²¾ç»†ç»“æ„ (Need high spatial resolution to capture fine structures)ï¼Œæ‰©å±•åˆ°é«˜åˆ†è¾¨ç‡éåŒå°å¯ (Scaling to high resolutions is nontrivial!) (å†…å­˜å ç”¨é‡å¤§ï¼Œ1024^3ä½“ç´ ç½‘æ ¼å ç”¨4GBå†…å­˜) [27:58]ã€‚
        -   **å¤„ç†ä½“ç´ è¾“å…¥ï¼š3Då·ç§¯ (Processing Voxel Inputs: 3D Convolution)** [16:55]
            -   æ¶æ„ï¼š3D ShapeNets (åŸºäºè®ºæ–‡ "3D ShapeNets: A Deep Representation for Volumetric Shapes", CVPR 2015)ã€‚
            -   è¾“å…¥ï¼šä½“ç´ ç½‘æ ¼ (1 x 30 x 30 x 30)ï¼Œè¡¨ç¤ºç©ºé—´ä¸­æ¯ä¸ªç‚¹çš„å ç”¨çŠ¶æ€ (binary occupancy)ã€‚
            -   ç½‘ç»œç»“æ„ï¼šå¤šå±‚3Då·ç§¯å±‚ (å¦‚6x6x6, 5x5x5, 4x4x4 å·ç§¯æ ¸)ï¼Œç‰¹å¾ç»´åº¦é€æ¸å¢åŠ ï¼Œç©ºé—´ç»´åº¦é€æ¸å‡å°ã€‚
            -   æœ«ç«¯ï¼šå…¨è¿æ¥å±‚ (FC Layer) é¢„æµ‹ç±»åˆ«åˆ†æ•° (Class Scores)ã€‚
            -   è®­ç»ƒï¼šåˆ†ç±»æŸå¤±å‡½æ•° (classification loss)ã€‚
        -   **ç”Ÿæˆä½“ç´ å½¢çŠ¶ï¼š3Då·ç§¯ (Generating Voxel Shapes: 3D Convolution)** [21:05]
            -   ä»»åŠ¡ï¼šè¾“å…¥2Då›¾åƒï¼Œè¾“å‡º3Dä½“ç´ ç½‘æ ¼ã€‚
            -   æ¶æ„ï¼š2D CNN (å¤„ç†è¾“å…¥å›¾åƒ) -> å…¨è¿æ¥å±‚ (FC Layer, å°†2Dç‰¹å¾è½¬æ¢ä¸º3Dç‰¹å¾) -> 3D CNN (å¸¦æœ‰ç©ºé—´ä¸Šé‡‡æ ·ï¼Œå¢åŠ ä½“ç´ åˆ†è¾¨ç‡) -> ä½“ç´ è¾“å‡ºã€‚
            -   è®­ç»ƒï¼šé€ä½“ç´ äº¤å‰ç†µæŸå¤± (per-voxel cross-entropy loss)ã€‚
            -   è®¡ç®—æˆæœ¬é«˜ï¼š3Då·ç§¯æ“ä½œçš„è®¡ç®—é‡ä¸ç©ºé—´å°ºå¯¸çš„ç«‹æ–¹æˆæ­£æ¯”ã€‚
        -   **ä½“ç´ æ‰©å±•æ–¹æ³• (Scaling Voxels)**:
            -   **å…«å‰æ ‘ (Oct-Trees)** [29:15]
                -   ä½¿ç”¨å…·æœ‰å¼‚æ„åˆ†è¾¨ç‡çš„ä½“ç´ ç½‘æ ¼ (Use voxel grids with heterogeneous resolution!)ã€‚
                -   åœ¨ä½åˆ†è¾¨ç‡ä¸‹æ•æ‰ç²—ç•¥ç»“æ„ï¼Œåœ¨éœ€è¦ç»†èŠ‚çš„åœ°æ–¹ä½¿ç”¨æ›´é«˜åˆ†è¾¨ç‡ã€‚
            -   **åµŒå¥—å½¢çŠ¶å±‚ (Nested Shape Layers)** [30:14]
                -   å°†å½¢çŠ¶é¢„æµ‹ä¸ºæ­£ç©ºé—´å’Œè´Ÿç©ºé—´çš„ç»„åˆ (Predict shape as a composition of positive and negative spaces)ã€‚
                -   ç±»ä¼¼äºä¿„ç½—æ–¯å¥—å¨ƒ (Matryoshka Russian dolls)ã€‚
                -   é€šè¿‡ç¨€ç–ä½“ç´ å±‚ä»å†…å‘å¤–è¡¨ç¤ºå½¢çŠ¶ (Represent shape from inside out using sparse voxel layers)ã€‚
            -   **ä½“ç´ ç®¡ (Voxel Tubes)** [24:16]
                -   ä¸€ç§ç‰¹æ®Šçš„æ¶æ„ï¼Œåªä½¿ç”¨2Då·ç§¯è¿›è¡Œä½“ç´ ç”Ÿæˆï¼Œä½†ç‰ºç‰²äº†Zè½´çš„å¹³ç§»ä¸å˜æ€§ (loses translational invariance in the Z dimension)ã€‚
                -   åœ¨2D CNNçš„æœ€åä¸€å±‚ï¼Œè¾“å‡ºçš„Vä¸ªæ»¤æ³¢å™¨è¢«è§£é‡Šä¸ºæ²¿æ·±åº¦ç»´åº¦çš„â€œä½“ç´ ç®¡â€åˆ†æ•°ã€‚
    -   **éšå¼æ›²é¢ (Implicit Surface)** [31:11, 31:19]
        -   å®šä¹‰ï¼šå­¦ä¹ ä¸€ä¸ªå‡½æ•° $o: \mathbb{R}^3 \rightarrow \{0, 1\}$ï¼Œç”¨äºåˆ†ç±»ä¸‰ç»´ç©ºé—´ä¸­çš„ä»»æ„ç‚¹æ˜¯ä½äºå½¢çŠ¶å†…éƒ¨è¿˜æ˜¯å¤–éƒ¨ (Learn a function to classify arbitrary 3D points as inside / outside the shape)ã€‚
        -   ä¸‰ç»´å¯¹è±¡çš„è¡¨é¢æ˜¯è¯¥å‡½æ•°çš„æ°´å¹³é›† (The surface of the 3D object is the level set): $\{x : o(x) = 1/2\}$ã€‚
        -   åˆ«åï¼šç¬¦å·è·ç¦»å‡½æ•° (signed distance function, SDF)ã€‚SDFç»™å‡ºåˆ°å½¢çŠ¶è¡¨é¢çš„æ¬§å‡ é‡Œå¾—è·ç¦» (Euclidean distance)ï¼Œç¬¦å·è¡¨ç¤ºå†…éƒ¨æˆ–å¤–éƒ¨ã€‚
        -   **å®ç°ä¸è®­ç»ƒ (Implementation and Training)** [33:43]
            -   è®­ç»ƒæ–¹å¼ï¼šç¥ç»ç½‘ç»œå°†3Dåæ ‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºè¯¥ç‚¹æ˜¯ä½äºå½¢çŠ¶å†…éƒ¨è¿˜æ˜¯å¤–éƒ¨çš„æ¦‚ç‡ã€‚
            -   å¤šå°ºåº¦è¾“å‡º (multiscale outputs)ï¼šå…è®¸åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹è¯„ä¼°å‡½æ•°ï¼Œç±»ä¼¼äºOct-Treesã€‚
            -   æå–æ˜¾å¼å½¢çŠ¶è¾“å‡º (Extracting explicit shape outputs)ï¼šéœ€è¦åå¤„ç†ã€‚
                -   é€šå¸¸é€šè¿‡Marching Cubesç®—æ³•åœ¨éšå¼å‡½æ•°ä¸Šæå–ç­‰å€¼é¢æ¥ç”Ÿæˆç½‘æ ¼ã€‚
                -   ç”Ÿæˆçš„ç½‘æ ¼å¯ä»¥è¿›ä¸€æ­¥ç®€åŒ– (simplify mesh) å’Œä½¿ç”¨æ¢¯åº¦ç»†åŒ– (refine using gradients)ã€‚
    -   **ç‚¹äº‘ (Point Cloud)** [31:02, 35:17]
        -   å®šä¹‰ï¼šç”¨Pä¸ªç‚¹çš„é›†åˆåœ¨ä¸‰ç»´ç©ºé—´ä¸­è¡¨ç¤ºå½¢çŠ¶ (Represent shape as a set of P points in 3D space)ã€‚è¿™äº›ç‚¹é€šå¸¸è¦†ç›–å¯¹è±¡è¡¨é¢ã€‚
        -   ä¼˜åŠ¿ï¼šå¯ä»¥è¡¨ç¤ºç²¾ç»†ç»“æ„è€Œæ— éœ€å¤§é‡ç‚¹ (Can represent fine structures without huge numbers of points)ï¼›æ›´å…·é€‚åº”æ€§ (more adaptive)ã€‚
        -   åŠ£åŠ¿ï¼šéœ€è¦æ–°çš„æ¶æ„å’ŒæŸå¤±å‡½æ•° (Requires new architecture, losses, etc)ï¼›ä¸ç›´æ¥è¡¨ç¤ºè¡¨é¢ (Doesn't explicitly represent the surface of the shape)ï¼›æå–ç½‘æ ¼éœ€è¦åå¤„ç† (extracting a mesh for rendering or other applications requires post-processing)ã€‚
        -   åº”ç”¨ï¼šè‡ªåŠ¨é©¾é©¶æ±½è½¦ (self-driving car applications) ä¸­çš„LiDARä¼ æ„Ÿå™¨æ•°æ®å¸¸ä»¥ç‚¹äº‘å½¢å¼è¡¨ç¤ºã€‚
        -   **å¤„ç†ç‚¹äº‘è¾“å…¥ï¼šPointNet (Processing Pointcloud Inputs: PointNet)** [38:44]
            -   ç›®æ ‡ï¼šå°†ç‚¹äº‘ä½œä¸ºé›†åˆå¤„ç† (Want to process pointclouds as sets)ï¼Œç‚¹çš„é¡ºåºä¸åº”å½±å“ç»“æœ (order should not matter)ã€‚
            -   æ¶æ„ï¼šè¾“å…¥ç‚¹äº‘ (P x 3) -> å¯¹æ¯ä¸ªç‚¹è¿è¡ŒMLP -> Max-Pool (æœ€å¤§æ± åŒ–) -> å…¨è¿æ¥å±‚ (Fully Connected)ã€‚
            -   MLPåœ¨æ¯ä¸ªç‚¹ä¸Šç‹¬ç«‹è¿è¡Œï¼Œç”Ÿæˆç‚¹ç‰¹å¾ (P x D)ã€‚
            -   æœ€å¤§æ± åŒ–æ“ä½œåœ¨æ‰€æœ‰ç‚¹ç‰¹å¾ä¸Šè¿›è¡Œï¼Œç”Ÿæˆä¸€ä¸ªå…¨å±€ç‰¹å¾å‘é‡ (Pooled vector: D)ï¼Œç¡®ä¿å¯¹ç‚¹é¡ºåºçš„ä¸å˜æ€§ã€‚
            -   æœ€åé€šè¿‡å…¨è¿æ¥å±‚è¾“å‡ºåˆ†ç±»åˆ†æ•° (Class score: C)ã€‚
        -   **ç”Ÿæˆç‚¹äº‘è¾“å‡º (Generating Pointcloud Outputs)** [42:16]
            -   ä»»åŠ¡ï¼šè¾“å…¥å•å¼ RGBå›¾åƒï¼Œè¾“å‡ºç‚¹äº‘ã€‚
            -   æ¶æ„ï¼š2D CNN -> å›¾åƒç‰¹å¾ (Image Features) -> ä¸¤ä¸ªåˆ†æ”¯ï¼š
                -   å…¨è¿æ¥åˆ†æ”¯ (Fully connected branch) -> P1ä¸ªç‚¹ (P1 x 3)ã€‚
                -   å·ç§¯åˆ†æ”¯ (Convolutional branch) -> P2ä¸ªç‚¹ (P2 x 3 x H' x W')ã€‚
                -   å°†ä¸¤éƒ¨åˆ†ç‚¹åˆå¹¶å¾—åˆ°æœ€ç»ˆç‚¹äº‘ $((P1 + H'W'P2) \times 3)$ã€‚
        -   **é¢„æµ‹ç‚¹äº‘ï¼šæŸå¤±å‡½æ•° (Predicting Point Clouds: Loss Function)** [45:05]
            -   éœ€è¦ä¸€ä¸ªå¯å¾®åˆ†çš„æ–¹å¼æ¥æ¯”è¾ƒç‚¹äº‘ä½œä¸ºé›†åˆ (We need a (differentiable) way to compare pointclouds as sets!)ã€‚
            -   **Chamfer è·ç¦» (Chamfer distance)**:
                -   å®šä¹‰ï¼šç‚¹äº‘ $S_1$ å’Œ $S_2$ ä¹‹é—´çš„Chamferè·ç¦»æ˜¯ $S_1$ ä¸­æ¯ä¸ªç‚¹åˆ° $S_2$ ä¸­æœ€è¿‘ç‚¹çš„L2è·ç¦»ä¹‹å’Œï¼ŒåŠ ä¸Š $S_2$ ä¸­æ¯ä¸ªç‚¹åˆ° $S_1$ ä¸­æœ€è¿‘ç‚¹çš„L2è·ç¦»ä¹‹å’Œã€‚
                -   å…¬å¼: $d_{CD}(S_1, S_2) = \sum_{x \in S_1} \min_{y \in S_2} \|x - y\|_2^2 + \sum_{y \in S_2} \min_{x \in S_1} \|x - y\|_2^2$ã€‚
                -   åªæœ‰å½“ä¸¤ä¸ªç‚¹äº‘å®Œç¾é‡åˆæ—¶ï¼Œè·ç¦»æ‰ä¸º0ã€‚
                -   é—®é¢˜ï¼šå¯¹å¼‚å¸¸å€¼ (outliers) éå¸¸æ•æ„Ÿ (very sensitive to outliers!)ã€‚
            -   **F1 åˆ†æ•° (F1 Score)** [57:55]
                -   ç±»ä¼¼äºChamferè·ç¦»ï¼Œä»é¢„æµ‹å’ŒçœŸå®å½¢çŠ¶è¡¨é¢é‡‡æ ·ç‚¹ã€‚
                -   ç²¾ç¡®åº¦@t (Precision@t) = é¢„æµ‹ç‚¹ä¸­åœ¨çœŸå®ç‚¹æŸä¸ªé˜ˆå€¼tå†…çš„æ¯”ä¾‹ã€‚
                -   å¬å›ç‡@t (Recall@t) = çœŸå®ç‚¹ä¸­åœ¨é¢„æµ‹ç‚¹æŸä¸ªé˜ˆå€¼tå†…çš„æ¯”ä¾‹ã€‚
                -   F1@t = $2 \times (\text{Precision@t} \times \text{Recall@t}) / (\text{Precision@t} + \text{Recall@t})$ã€‚
                -   å¯¹å¼‚å¸¸å€¼æ›´é²æ£’ (F1 score is robust to outliers!)ã€‚
                -   ç»“è®ºï¼šF1åˆ†æ•°å¯èƒ½æ˜¯ç›®å‰æœ€å¸¸ç”¨çš„3Då½¢çŠ¶é¢„æµ‹åº¦é‡æ ‡å‡†ã€‚
    -   **ç½‘æ ¼ (Mesh)** [31:02, 49:54]
        -   å®šä¹‰ï¼šå°†ä¸‰ç»´å½¢çŠ¶è¡¨ç¤ºä¸ºä¸‰è§’å½¢çš„é›†åˆ (Represent a 3D shape as a set of triangles)ã€‚åŒ…å«é¡¶ç‚¹ (Vertices) å’Œé¢ (Faces)ã€‚
        -   ä¼˜åŠ¿ï¼šå›¾å½¢å­¦ä¸­çš„æ ‡å‡†è¡¨ç¤º (Standard representation for graphics)ï¼›æ˜ç¡®è¡¨ç¤º3Då½¢çŠ¶ (Explicitly represents 3D shapes)ï¼›å…·æœ‰é€‚åº”æ€§ (Adaptive) (å¯ä»¥é«˜æ•ˆè¡¨ç¤ºå¹³å¦è¡¨é¢ï¼Œä¸ºç²¾ç»†ç»†èŠ‚åŒºåŸŸåˆ†é…æ›´å¤šé¢)ã€‚
        -   å¯ä»¥åœ¨é¡¶ç‚¹ä¸Šé™„åŠ æ•°æ®å¹¶é€šè¿‡æ•´ä¸ªè¡¨é¢è¿›è¡Œæ’å€¼ (Can attach data on verts and interpolate over the whole surface)ï¼šRGBé¢œè‰²ã€çº¹ç†åæ ‡ã€æ³•çº¿å‘é‡ç­‰ã€‚
        -   åŠ£åŠ¿ï¼šç”¨ç¥ç»ç½‘ç»œå¤„ç†éå¹³å‡¡ (Nontrivial to process with neural nets!)ã€‚
        -   **é¢„æµ‹ç½‘æ ¼ï¼šPixel2Mesh (Predicting Meshes: Pixel2Mesh)** [56:21]
            -   è¾“å…¥ï¼šå•å¼ RGBå›¾åƒã€‚è¾“å‡ºï¼šå¯¹è±¡çš„ä¸‰è§’å½¢ç½‘æ ¼ã€‚
            -   **æ ¸å¿ƒæ€æƒ³ (Key Ideas)**:
                1.  **è¿­ä»£ç»†åŒ– (Iterative Refinement)** [57:33]: ä»åˆå§‹æ¤­çƒä½“ç½‘æ ¼å¼€å§‹ -> ç½‘ç»œé¢„æµ‹æ¯ä¸ªé¡¶ç‚¹çš„åç§»é‡ -> é‡å¤è¿›è¡Œç½‘æ ¼å˜å½¢ã€å›¾è§£æ± åŒ–ç­‰æ“ä½œï¼Œé€æ­¥å¢åŠ é¡¶ç‚¹æ•°é‡å¹¶ç»†åŒ–ç½‘æ ¼ï¼Œä½¿å…¶ä¸è¾“å…¥å›¾åƒçš„å‡ ä½•å½¢çŠ¶åŒ¹é…ã€‚
                2.  **å›¾å·ç§¯ (Graph Convolution)** [58:59]:
                    -   è¾“å…¥ï¼šå¸¦æœ‰æ¯ä¸ªé¡¶ç‚¹ç‰¹å¾å‘é‡çš„å›¾ã€‚
                    -   æ–°çš„é¡¶ç‚¹ç‰¹å¾ä¾èµ–äºå…¶è‡ªèº«ç‰¹å¾å’Œç›¸é‚»é¡¶ç‚¹ç‰¹å¾çš„åŠ æƒå’Œã€‚
                    -   ä½¿ç”¨ç›¸åŒçš„æƒé‡è®¡ç®—æ‰€æœ‰è¾“å‡ºï¼Œå®ç°ç±»ä¼¼å·ç§¯çš„å±€éƒ¨ç‰¹å¾èšåˆã€‚
                    -   èƒ½å¤Ÿå¤„ç†å…·æœ‰ä»»æ„æ‹“æ‰‘ç»“æ„çš„å›¾ã€‚
                3.  **é¡¶ç‚¹å¯¹é½ç‰¹å¾ (Vertex-Aligned Features)** [01:00:10]:
                    -   å¯¹äºç½‘æ ¼ä¸­çš„æ¯ä¸ªé¡¶ç‚¹ï¼Œä½¿ç”¨ç›¸æœºä¿¡æ¯æŠ•å½±åˆ°å›¾åƒå¹³é¢ã€‚
                    -   ä½¿ç”¨åŒçº¿æ€§æ’å€¼ (bilinear interpolation) ä»2D CNNæå–çš„å›¾åƒç‰¹å¾å›¾ä¸­é‡‡æ ·å¯¹åº”ä½ç½®çš„ç‰¹å¾ã€‚
                    -   è¿™ç±»ä¼¼äºRoI-Alignæ“ä½œï¼Œä¿æŒè¾“å…¥å›¾åƒå’Œç‰¹å¾å‘é‡ä¹‹é—´çš„å¯¹é½ï¼Œå°†å›¾åƒä¿¡æ¯æ•´åˆåˆ°3Dç½‘æ ¼ä¸­ã€‚
                4.  **Chamfer æŸå¤±å‡½æ•° (Chamfer Loss Function)** [01:00:10]: ç”¨äºæ¯”è¾ƒé¢„æµ‹ç½‘æ ¼å’ŒçœŸå®ç½‘æ ¼ã€‚
                    -   é€šè¿‡å¯¹ç½‘æ ¼è¡¨é¢é‡‡æ ·ç‚¹æ¥å°†å…¶è½¬æ¢ä¸ºç‚¹äº‘ï¼Œç„¶åè®¡ç®—ç‚¹äº‘ä¹‹é—´çš„Chamferè·ç¦»ã€‚
                    -   é—®é¢˜ï¼šéœ€è¦åœ¨çº¿é‡‡æ · (Need to sample online!) (æ•ˆç‡æ˜¯å…³é”®)ï¼›éœ€è¦é€šè¿‡é‡‡æ ·è¿›è¡Œåå‘ä¼ æ’­ (Need to backprop through sampling!)ã€‚
        -   **Mesh R-CNN: å½¢çŠ¶æ­£åˆ™åŒ– (Shape Regularizers)** [01:10:09]
            -   ä»…ä½¿ç”¨ChamferæŸå¤±ä¼šå¯¼è‡´ç½‘æ ¼é€€åŒ– (Using Chamfer as only mesh loss gives degenerate meshes)ï¼ˆä¾‹å¦‚ï¼Œäº§ç”Ÿâ€œç ´ç¢â€çš„è¡¨é¢ï¼‰ã€‚
            -   éœ€è¦â€œç½‘æ ¼æ­£åˆ™åŒ–å™¨â€ (mesh regularizer) æ¥é¼“åŠ±è‰¯å¥½çš„é¢„æµ‹ (to encourage nice predictions!)ï¼šä¾‹å¦‚ï¼Œæœ€å°åŒ–é¢„æµ‹ç½‘æ ¼ä¸­è¾¹çš„L2èŒƒæ•° ($L_{edge}$ = minimize L2 norm of edges in the predicted mesh)ã€‚è¿™æœ‰åŠ©äºç”Ÿæˆæ›´å¹³æ»‘ã€ç»“æ„æ›´åˆç†çš„ç½‘æ ¼ã€‚
        -   **Mesh R-CNN: æ··åˆ3Då½¢çŠ¶è¡¨ç¤º (Hybrid 3D shape representation)** [01:13:58]
            -   ç»“åˆä½“ç´ é¢„æµ‹å’Œç½‘æ ¼å˜å½¢çš„ä¼˜ç‚¹ã€‚
            -   é€šè¿‡ä½“ç´ é¢„æµ‹åˆ›å»ºåˆå§‹ç½‘æ ¼é¢„æµ‹ (Use voxel predictions to create initial mesh prediction!)ï¼Œè§£å†³ç½‘æ ¼å˜å½¢æ–¹æ³•æ— æ³•æ”¹å˜æ‹“æ‰‘ç»“æ„ï¼ˆå¦‚å­”æ´ï¼‰çš„é™åˆ¶ã€‚
            -   **Mesh R-CNN æµç¨‹ (Pipeline)** [01:15:35]:
                1.  2Dç‰©ä½“è¯†åˆ« (2D object recognition): è¾“å…¥å›¾åƒ -> Mask R-CNN -> è¾“å‡ºè¾¹ç•Œæ¡†å’Œæ©ç é¢„æµ‹ã€‚
                2.  3Dç‰©ä½“ä½“ç´  (3D object voxels): ä»2Dé¢„æµ‹ä¸­æå–ç²—ç•¥çš„3Dä½“ç´ è¡¨ç¤ºã€‚
                3.  3Dç‰©ä½“ç½‘æ ¼ (3D object meshes): å°†ä½“ç´ è½¬æ¢ä¸ºå—çŠ¶ç½‘æ ¼ï¼Œç„¶åè¿›è¡Œè¿­ä»£ç»†åŒ–ã€‚
            -   ç»“æœï¼šèƒ½å¤Ÿé¢„æµ‹å…·æœ‰å¤æ‚æ‹“æ‰‘ç»“æ„ï¼ˆå¦‚ä¹¦æ¶ä¸Šçš„å­”æ´ï¼‰çš„ç½‘æ ¼ã€‚
            -   Amodal è¡¥å…¨ (Amodal completion): é¢„æµ‹å¯¹è±¡çš„è¢«é®æŒ¡éƒ¨åˆ† (predict occluded parts of objects)ã€‚
            -   å±€é™æ€§ï¼šåˆ†å‰²å¤±è´¥ (segmentation failures) ä¼šä¼ æ’­åˆ°ç½‘æ ¼ (propagate to meshes)ã€‚

-   **ç›¸æœºä¸åæ ‡ç³» (Cameras & Coordinate Systems)** [01:02:59]
    -   ç›¸æœºç³»ç»Ÿåœ¨3Dä¸­å˜å¾—å¤æ‚ (Cameras get complicated in 3D)ã€‚
    -   **è§„èŒƒåæ ‡ (Canonical Coordinates)** [01:03:00]
        -   å®šä¹‰ï¼šåœ¨ä¸€ä¸ªè§„èŒƒåæ ‡ç³»ä¸­é¢„æµ‹3Då½¢çŠ¶ (Predict 3D shape in a canonical coordinate system)ï¼Œä¾‹å¦‚ï¼Œæ¤…å­çš„æ­£é¢æ˜¯+zæ–¹å‘ï¼Œè¿™ä¸è¾“å…¥å›¾åƒçš„è§†è§’æ— å…³ã€‚
        -   è®¸å¤šè®ºæ–‡éƒ½åœ¨è§„èŒƒåæ ‡ä¸­è¿›è¡Œé¢„æµ‹ï¼Œå› ä¸ºæ•°æ®åŠ è½½æ›´ç®€å• (Many papers predict in canonical coordinates â€“ easier to load data)ã€‚
        -   é—®é¢˜ï¼šè§„èŒƒè§†å›¾æ‰“ç ´äº†â€œç‰¹å¾å¯¹é½åŸåˆ™â€(Canonical view breaks the "principle of feature alignment")ï¼Œå³é¢„æµ‹åº”è¯¥ä¸è¾“å…¥å¯¹é½ã€‚
    -   **è§†å›¾åæ ‡ (View Coordinates)** [01:05:46]
        -   å®šä¹‰ï¼šé¢„æµ‹ä¸ç›¸æœºè§†è§’å¯¹é½çš„3Då½¢çŠ¶ (Predict 3D shape aligned to the viewpoint of the camera)ã€‚
        -   è§†å›¾åæ ‡ä¿æŒäº†è¾“å…¥å’Œé¢„æµ‹ä¹‹é—´çš„å¯¹é½ (View coordinates maintain alignment between inputs and predictions!)ã€‚
        -   ç ”ç©¶è¡¨æ˜ï¼Œåœ¨è§†å›¾åæ ‡ç³»ä¸­è®­ç»ƒçš„ç½‘ç»œåœ¨æµ‹è¯•æ—¶å¯¹å·²çŸ¥å½¢çŠ¶çš„æ–°è§†å›¾ã€æ–°æ¨¡å‹å’Œæ–°ç±»åˆ«å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚
        -   è§†å›¾ä¸­å¿ƒä½“ç´ é¢„æµ‹ (View-centric voxel predictions): ä½“ç´ è€ƒè™‘é€è§†ç›¸æœºï¼Œå› æ­¤â€œä½“ç´ â€å®é™…ä¸Šæ˜¯è§†é”¥ (frustums)ã€‚

-   **3Dæ•°æ®é›† (3D Datasets)** [01:06:50]
    -   **ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ•°æ®é›† (Object-Centric Datasets)**:
        -   **ShapeNet**: åŒ…å«çº¦50ä¸ªç±»åˆ«å’Œ5ä¸‡ä¸ª3D CADæ¨¡å‹ã€‚æ ‡å‡†åˆ’åˆ†æœ‰13ä¸ªç±»åˆ«ï¼Œçº¦4.4ä¸‡ä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹æœ‰25å¼ æ¸²æŸ“å›¾åƒã€‚
            -   ç¼ºç‚¹ï¼šåˆæˆçš„ (Synthetic)ï¼Œå­¤ç«‹çš„å¯¹è±¡ (isolated objects)ï¼›æ— ä¸Šä¸‹æ–‡ (no context)ã€‚å¤§é‡æ¤…å­ã€æ±½è½¦ã€é£æœºï¼ˆç±»åˆ«ä¸å¹³è¡¡ï¼‰ã€‚
        -   **Pix3D**: 9ä¸ªç±»åˆ«ï¼Œ219ä¸ªå®œå®¶å®¶å…·3Dæ¨¡å‹ï¼Œå¯¹é½åˆ°çº¦1.7ä¸‡å¼ çœŸå®å›¾åƒã€‚
            -   ä¼˜ç‚¹ï¼šçœŸå®å›¾åƒ (Real images!)ï¼›æœ‰ä¸Šä¸‹æ–‡ (Context!)ã€‚
            -   ç¼ºç‚¹ï¼šå°è€Œå±€éƒ¨ (Small, partial annotations)ï¼ˆæ¯å¼ å›¾åƒåªæœ‰ä¸€ä¸ªå¯¹è±¡æ³¨é‡Šï¼‰ã€‚

### äºŒã€å…³é”®æœ¯è¯­å®šä¹‰ (Key Term Definitions)
-   **3Dè§†è§‰ (3D Vision)**: è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºä»å›¾åƒæˆ–è§†é¢‘ä¸­ç†è§£ä¸‰ç»´åœºæ™¯å’Œå¯¹è±¡çš„ç»“æ„ã€‚
-   **åˆ†ç±» (Classification)**: ä¸€ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œæ—¨åœ¨è¯†åˆ«å›¾åƒä¸­å­˜åœ¨çš„ä¸»è¦å¯¹è±¡ç±»åˆ«ã€‚
-   **è¯­ä¹‰åˆ†å‰² (Semantic Segmentation)**: ä¸€ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œä¸ºå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚â€œè‰åœ°â€ã€â€œçŒ«â€ã€â€œæ ‘â€ï¼‰ï¼Œè€Œä¸åŒºåˆ†åŒä¸€ç±»åˆ«çš„ä¸åŒå®ä¾‹ã€‚
-   **ç›®æ ‡æ£€æµ‹ (Object Detection)**: ä¸€ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œæ—¨åœ¨è¯†åˆ«å›¾åƒä¸­ç‰¹å®šå¯¹è±¡çš„å®ä¾‹ï¼Œå¹¶ç”¨è¾¹ç•Œæ¡†å®šä½å®ƒä»¬ï¼ŒåŒæ—¶ç»™å‡ºå…¶ç±»åˆ«ã€‚
-   **å®ä¾‹åˆ†å‰² (Instance Segmentation)**: ä¸€ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œç»“åˆäº†ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ï¼Œä¸ä»…è¯†åˆ«å’Œå®šä½æ¯ä¸ªå¯¹è±¡å®ä¾‹ï¼Œè¿˜ä¸ºæ¯ä¸ªå®ä¾‹æä¾›ç²¾ç¡®çš„åƒç´ çº§æ©ç ã€‚
-   **æ·±åº¦å›¾ (Depth Map)**: ä¸€ç§å›¾åƒè¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ çš„å€¼ä»£è¡¨ä»ç›¸æœºåˆ°è¯¥åƒç´ å¤„å¯¹åº”ä¸–ç•Œç‚¹ï¼ˆå¯¹è±¡ï¼‰çš„è·ç¦»ã€‚
-   **RGB-Då›¾åƒ (RGB-D Image)**: ç»“åˆäº†å½©è‰²ï¼ˆRGBï¼‰å›¾åƒå’Œæ·±åº¦å›¾ï¼ˆDï¼‰çš„å›¾åƒæ ¼å¼ï¼Œå¸¸ç”¨äºè¡¨ç¤º2.5ç»´æ•°æ®ã€‚
-   **å°ºåº¦/æ·±åº¦æ¨¡ç³Šæ€§ (Scale / Depth Ambiguity)**: åœ¨å•å¼ å›¾åƒä¸­ï¼Œç”±äºé€è§†æŠ•å½±ï¼Œå°è€Œè¿‘çš„ç‰©ä½“å¯èƒ½ä¸å¤§è€Œè¿œçš„ç‰©ä½“åœ¨è§†è§‰ä¸Šå‘ˆç°å‡ºç›¸åŒçš„å¤§å°å’Œå½¢çŠ¶ï¼Œå¯¼è‡´å…¶ç»å¯¹å°ºåº¦å’Œæ·±åº¦æ— æ³•ç¡®å®šã€‚
-   **å°ºåº¦ä¸å˜æŸå¤± (Scale invariant loss)**: ä¸€ç§æŸå¤±å‡½æ•°ï¼Œåœ¨è®­ç»ƒç¥ç»ç½‘ç»œé¢„æµ‹æ·±åº¦å›¾æ—¶ï¼Œä¸æƒ©ç½šé¢„æµ‹æ·±åº¦ä¸çœŸå®æ·±åº¦ä¹‹é—´çš„å…¨å±€å°ºåº¦åå·®ï¼Œä»¥è§£å†³å°ºåº¦/æ·±åº¦æ¨¡ç³Šæ€§é—®é¢˜ã€‚
-   **è¡¨é¢æ³•çº¿ (Surface Normals)**: åœ¨3Då‡ ä½•ä¸­ï¼Œä¸è¡¨é¢æ­£äº¤çš„å‘é‡ï¼Œç”¨äºæè¿°è¡¨é¢çš„æ–¹å‘å’Œå±€éƒ¨å‡ ä½•å½¢çŠ¶ã€‚
-   **ä½“ç´ ç½‘æ ¼ (Voxel Grid)**: ä¸€ç§ä¸‰ç»´ç¦»æ•£è¡¨ç¤ºï¼Œå°†ä¸‰ç»´ç©ºé—´åˆ’åˆ†ä¸ºå°çš„ç«‹æ–¹ä½“å•å…ƒï¼ˆä½“ç´ ï¼‰ï¼Œæ¯ä¸ªä½“ç´ å¯ä»¥è¡¨ç¤ºæ˜¯å¦è¢«ç‰©ä½“å ç”¨ï¼ˆ0æˆ–1ï¼‰ï¼Œç±»ä¼¼äº2Då›¾åƒä¸­çš„åƒç´ ç½‘æ ¼ã€‚
-   **3Då·ç§¯ (3D Convolution)**: å·ç§¯æ“ä½œåœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„æ‰©å±•ï¼Œä½¿ç”¨ä¸‰ç»´å·ç§¯æ ¸åœ¨ä¸‰ç»´è¾“å…¥æ•°æ®ï¼ˆå¦‚ä½“ç´ ç½‘æ ¼ï¼‰ä¸Šè¿›è¡Œæ»‘åŠ¨å’Œç‰¹å¾æå–ã€‚
-   **å…«å‰æ ‘ (Oct-Trees)**: ä¸€ç§åˆ†å±‚æ•°æ®ç»“æ„ï¼Œç”¨äºé«˜æ•ˆåœ°è¡¨ç¤ºå’Œå­˜å‚¨ç¨€ç–çš„3Dä½“ç´ æ•°æ®ï¼Œé€šè¿‡åœ¨ä¸åŒåŒºåŸŸä½¿ç”¨ä¸åŒçš„åˆ†è¾¨ç‡æ¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚
-   **åµŒå¥—å½¢çŠ¶å±‚ (Nested Shape Layers)**: ä¸€ç§å°†å½¢çŠ¶é¢„æµ‹ä¸ºæ­£ç©ºé—´å’Œè´Ÿç©ºé—´ç»„åˆçš„æ–¹æ³•ï¼Œé€šè¿‡å¤šå±‚ç¨€ç–ä½“ç´ è¡¨ç¤ºæ¥æ•æ‰ä¸åŒå°ºåº¦çš„å½¢çŠ¶ä¿¡æ¯ã€‚
-   **ä½“ç´ ç®¡ (Voxel Tubes)**: ä¸€ç§åˆ©ç”¨2Då·ç§¯æ¥é—´æ¥ç”Ÿæˆ3Dä½“ç´ è¡¨ç¤ºçš„æ–¹æ³•ï¼Œé€šè¿‡å°†æ·±åº¦ä¿¡æ¯ç¼–ç ä¸ºç‰¹å¾é€šé“ã€‚
-   **éšå¼å‡½æ•° (Implicit Function)**: ä¸€ç§æ•°å­¦å‡½æ•°ï¼Œå…¶é›¶å€¼é›†ï¼ˆæˆ–æŸä¸ªç‰¹å®šæ°´å¹³é›†ï¼‰å®šä¹‰äº†å‡ ä½•å½¢çŠ¶çš„è¡¨é¢ï¼Œå¯ä»¥å­¦ä¹ æ¥åˆ†ç±»ä¸‰ç»´ç©ºé—´ä¸­çš„ç‚¹æ˜¯ä½äºå½¢çŠ¶å†…éƒ¨è¿˜æ˜¯å¤–éƒ¨ã€‚
-   **ç¬¦å·è·ç¦»å‡½æ•° (Signed Distance Function, SDF)**: ä¸€ç§ç‰¹æ®Šçš„éšå¼å‡½æ•°ï¼Œå…¶å€¼è¡¨ç¤ºç©ºé—´ä¸­ä»»æ„ç‚¹åˆ°æœ€è¿‘è¡¨é¢ç‚¹çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œå…¶ç¬¦å·è¡¨ç¤ºè¯¥ç‚¹ä½äºè¡¨é¢å†…éƒ¨ï¼ˆè´Ÿå€¼ï¼‰è¿˜æ˜¯å¤–éƒ¨ï¼ˆæ­£å€¼ï¼‰ã€‚
-   **ç‚¹äº‘ (Point Cloud)**: ç”±ä¸‰ç»´ç©ºé—´ä¸­çš„ä¸€ç³»åˆ—ç‚¹ç»„æˆçš„æ•°æ®é›†ï¼Œç”¨äºè¡¨ç¤ºç‰©ä½“çš„è¡¨é¢æˆ–ç©ºé—´ç»“æ„ã€‚
-   **Chamfer è·ç¦» (Chamfer distance)**: ä¸€ç§ç”¨äºè¡¡é‡ä¸¤ä¸ªç‚¹é›†ä¹‹é—´ç›¸ä¼¼åº¦çš„åº¦é‡ï¼Œè®¡ç®—ä¸€ä¸ªé›†åˆä¸­æ¯ä¸ªç‚¹åˆ°å¦ä¸€ä¸ªé›†åˆä¸­æœ€è¿‘ç‚¹çš„è·ç¦»ä¹‹å’Œã€‚
-   **F1 åˆ†æ•° (F1 Score)**: åœ¨åˆ†ç±»ä»»åŠ¡ä¸­å¸¸ç”¨çš„åº¦é‡ï¼Œæ˜¯ç²¾ç¡®åº¦ (Precision) å’Œå¬å›ç‡ (Recall) çš„è°ƒå’Œå¹³å‡å€¼ï¼Œå¯ä»¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚
-   **ç½‘æ ¼ (Mesh)**: ä¸€ç§ç”±é¡¶ç‚¹ã€è¾¹å’Œé¢ï¼ˆé€šå¸¸æ˜¯ä¸‰è§’å½¢æˆ–å››è¾¹å½¢ï¼‰ç»„æˆçš„3Då‡ ä½•è¡¨ç¤ºï¼Œç”¨äºæè¿°ç‰©ä½“çš„è¡¨é¢ã€‚
-   **è¿­ä»£ç»†åŒ– (Iterative Refinement)**: ä¸€ç§é€æ­¥æ”¹è¿›æ¨¡å‹æˆ–é¢„æµ‹ç»“æœçš„æ–¹æ³•ï¼Œé€šå¸¸ä»ä¸€ä¸ªç²—ç•¥çš„åˆå§‹çŒœæµ‹å¼€å§‹ï¼Œé€šè¿‡å¤šæ¬¡è¿­ä»£ä½¿å…¶é€æ¸æ¥è¿‘æœ€ç»ˆè§£ã€‚
-   **å›¾å·ç§¯ (Graph Convolution)**: ä¸€ç§ç”¨äºåœ¨å›¾ç»“æ„æ•°æ®ä¸Šè¿›è¡Œç‰¹å¾å­¦ä¹ çš„å·ç§¯æ“ä½œï¼Œé€šè¿‡èšåˆç›¸é‚»èŠ‚ç‚¹çš„ç‰¹å¾æ¥æ›´æ–°å½“å‰èŠ‚ç‚¹çš„ç‰¹å¾ã€‚
-   **é¡¶ç‚¹å¯¹é½ç‰¹å¾ (Vertex-Aligned Features)**: é€šè¿‡å°†3Dé¡¶ç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢ï¼Œå¹¶ä»å›¾åƒç‰¹å¾å›¾ä¸­é‡‡æ ·å¯¹åº”ä½ç½®çš„ç‰¹å¾ï¼Œä»è€Œå°†å›¾åƒç‰¹å¾ä¸3Dé¡¶ç‚¹å¯¹é½ã€‚
-   **Mesh Regularizer (ç½‘æ ¼æ­£åˆ™åŒ–å™¨)**: åœ¨è®­ç»ƒç¥ç»ç½‘ç»œç”Ÿæˆç½‘æ ¼æ—¶ï¼Œç”¨äºé¼“åŠ±ç”Ÿæˆå¹³æ»‘ã€éé€€åŒ–ç½‘æ ¼çš„é¢å¤–æŸå¤±é¡¹ï¼Œä¾‹å¦‚é™åˆ¶ç½‘æ ¼è¾¹çš„é•¿åº¦æˆ–ç½‘æ ¼é¢çš„é¢ç§¯ã€‚
-   **è§„èŒƒåæ ‡ (Canonical Coordinates)**: ä¸€ç§æ ‡å‡†åŒ–çš„3Dåæ ‡ç³»ç»Ÿï¼Œç”¨äºç»Ÿä¸€è¡¨ç¤ºæŸä¸€ç±»ç‰©ä½“ï¼ˆä¾‹å¦‚ï¼Œæ‰€æœ‰æ¤…å­éƒ½æœå‘åŒä¸€æ–¹å‘ï¼‰ï¼Œç‹¬ç«‹äºå…¶åœ¨åœºæ™¯ä¸­çš„å®é™…ä½ç½®å’Œå§¿æ€ã€‚
-   **è§†å›¾åæ ‡ (View Coordinates)**: ä¸€ç§3Dåæ ‡ç³»ç»Ÿï¼Œå…¶åŸç‚¹å’Œè½´å‘ä¸ç›¸æœºå¯¹é½ï¼Œè¡¨ç¤ºç‰©ä½“ç›¸å¯¹äºç›¸æœºçš„å§¿æ€ã€‚
-   **Amodal è¡¥å…¨ (Amodal Completion)**: é¢„æµ‹ç‰©ä½“å®Œæ•´çš„ä¸‰ç»´å½¢çŠ¶ï¼ŒåŒ…æ‹¬è¢«å…¶ä»–ç‰©ä½“é®æŒ¡ï¼ˆä¸å¯è§ï¼‰çš„éƒ¨åˆ†ã€‚

### ä¸‰ã€æ ¸å¿ƒç®—æ³•ä¸ä»£ç ç‰‡æ®µ (Core Algorithms & Code Snippets)

-   **é¢„æµ‹æ·±åº¦å›¾ (Predicting Depth Maps)**:
    -   æ¶æ„: å…¨å·ç§¯ç½‘ç»œ (Fully Convolutional network)
    -   æŸå¤±å‡½æ•°: é€åƒç´ L2è·ç¦»æŸå¤± (Per-pixel Loss (L2 Distance))ï¼Œå°ºåº¦ä¸å˜ (Scale invariant)ã€‚

-   **é¢„æµ‹è¡¨é¢æ³•çº¿ (Predicting Normals)**:
    -   æ¶æ„: å…¨å·ç§¯ç½‘ç»œ
    -   æŸå¤±å‡½æ•°: é€åƒç´ ç‚¹ç§¯æŸå¤± (Per-pixel Loss: $(x \cdot y) / (|x| |y|)$)ã€‚

-   **å¤„ç†ä½“ç´ è¾“å…¥ï¼š3Då·ç§¯ (Processing Voxel Inputs: 3D Convolution)**:
    -   æ¶æ„: 3D ShapeNetsã€‚
    -   è¾“å…¥ï¼šä½“ç´ ç½‘æ ¼ (1 x 30 x 30 x 30)ã€‚
    -   è®­ç»ƒ: åˆ†ç±»æŸå¤±å‡½æ•° (classification loss)ã€‚

-   **ç”Ÿæˆä½“ç´ å½¢çŠ¶ï¼š3Då·ç§¯ (Generating Voxel Shapes: 3D Convolution)**:
    -   ä»»åŠ¡ï¼šè¾“å…¥2Då›¾åƒï¼Œè¾“å‡º3Dä½“ç´ ç½‘æ ¼ã€‚
    -   æ¶æ„ï¼š2D CNN -> 3D Features -> 3D CNNã€‚
    -   è®­ç»ƒ: é€ä½“ç´ äº¤å‰ç†µæŸå¤± (per-voxel cross-entropy loss)ã€‚

-   **éšå¼å‡½æ•°ï¼šä»éšå¼è¡¨ç¤ºä¸­æå–å½¢çŠ¶ (Implicit Functions: Extracting Shapes from Implicit Representations)**:
    -   è®­ç»ƒæ–¹å¼ï¼šå­¦ä¹ ç¥ç»ç½‘ç»œï¼Œå°†3Dåæ ‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºè¯¥ç‚¹æ˜¯ä½äºå½¢çŠ¶å†…éƒ¨è¿˜æ˜¯å¤–éƒ¨çš„æ¦‚ç‡ã€‚
    -   æå–æ˜¾å¼å½¢çŠ¶è¾“å‡º: éœ€è¦åå¤„ç†ï¼ˆå¦‚Marching Cubesç®—æ³•ï¼‰ã€‚

-   **å¤„ç†ç‚¹äº‘è¾“å…¥ï¼šPointNet (Processing Pointcloud Inputs: PointNet)**:
    -   ç›®æ ‡ï¼šå°†ç‚¹äº‘ä½œä¸ºé›†åˆå¤„ç†ï¼Œç‚¹çš„é¡ºåºä¸åº”å½±å“ç»“æœã€‚
    -   æ¶æ„ï¼šè¾“å…¥ç‚¹äº‘ (P x 3) -> å¯¹æ¯ä¸ªç‚¹è¿è¡ŒMLP -> Max-Pool -> å…¨è¿æ¥å±‚ã€‚

-   **ç”Ÿæˆç‚¹äº‘è¾“å‡º (Generating Pointcloud Outputs)**:
    -   ä»»åŠ¡ï¼šè¾“å…¥å•å¼ RGBå›¾åƒï¼Œè¾“å‡ºç‚¹äº‘ã€‚
    -   æ¶æ„ï¼š2D CNN -> å›¾åƒç‰¹å¾ -> ä¸¤ä¸ªåˆ†æ”¯ï¼šå…¨è¿æ¥åˆ†æ”¯å’Œå·ç§¯åˆ†æ”¯ï¼Œæœ€ååˆå¹¶ç‚¹äº‘ã€‚

-   **é¢„æµ‹ç‚¹äº‘ï¼šæŸå¤±å‡½æ•° (Predicting Point Clouds: Loss Function)**:
    -   **Chamfer è·ç¦» (Chamfer distance)**:
        -   å…¬å¼: $d_{CD}(S_1, S_2) = \sum_{x \in S_1} \min_{y \in S_2} \|x - y\|_2^2 + \sum_{y \in S_2} \min_{x \in S_1} \|x - y\|_2^2$
    -   **F1 åˆ†æ•° (F1 Score)**:
        -   F1@t = $2 \times (\text{Precision@t} \times \text{Recall@t}) / (\text{Precision@t} + \text{Recall@t})$

-   **é¢„æµ‹ç½‘æ ¼ï¼šPixel2Mesh (Predicting Meshes: Pixel2Mesh)**:
    -   è¾“å…¥ï¼šå•å¼ RGBå›¾åƒã€‚è¾“å‡ºï¼šå¯¹è±¡çš„ä¸‰è§’å½¢ç½‘æ ¼ã€‚
    -   **æ ¸å¿ƒæ€æƒ³ (Key Ideas)**:
        1.  **è¿­ä»£ç»†åŒ– (Iterative Refinement)**: ä»åˆå§‹æ¤­çƒä½“ç½‘æ ¼å¼€å§‹ï¼Œç½‘ç»œé¢„æµ‹æ¯ä¸ªé¡¶ç‚¹çš„åç§»é‡ï¼Œå¹¶é‡å¤è¯¥è¿‡ç¨‹ç»†åŒ–ç½‘æ ¼ã€‚
        2.  **å›¾å·ç§¯ (Graph Convolution)**: æ–°çš„é¡¶ç‚¹ç‰¹å¾ä¾èµ–äºè‡ªèº«ç‰¹å¾å’Œç›¸é‚»é¡¶ç‚¹ç‰¹å¾ã€‚
        3.  **é¡¶ç‚¹å¯¹é½ç‰¹å¾ (Vertex-Aligned Features)**: å°†3Dé¡¶ç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢ï¼Œä»2D CNNçš„ç‰¹å¾å›¾ä¸­é‡‡æ ·ï¼Œå°†å›¾åƒä¿¡æ¯æ•´åˆåˆ°3Dç½‘æ ¼ä¸­ã€‚
        4.  **Chamfer æŸå¤±å‡½æ•° (Chamfer Loss Function)**: ç”¨äºæ¯”è¾ƒé¢„æµ‹ç½‘æ ¼å’ŒçœŸå®ç½‘æ ¼çš„æŸå¤±ã€‚

-   **Mesh R-CNN æµç¨‹ (Pipeline)**:
    1.  2Dç‰©ä½“è¯†åˆ« (Mask R-CNN): ä»è¾“å…¥å›¾åƒè·å–è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç ã€‚
    2.  3Dç‰©ä½“ä½“ç´ : ä»2Dé¢„æµ‹ç”Ÿæˆç²—ç•¥çš„3Dä½“ç´ ã€‚
    3.  3Dç‰©ä½“ç½‘æ ¼: å°†ä½“ç´ è½¬æ¢ä¸ºç½‘æ ¼ï¼Œç„¶åé€šè¿‡è¿­ä»£ç»†åŒ–è·å¾—é«˜ç²¾åº¦çš„ç½‘æ ¼é¢„æµ‹ã€‚
    -   **Mesh Regularizers (å½¢çŠ¶æ­£åˆ™åŒ–å™¨)**:
        -   $L_{edge}$ = æœ€å°åŒ–é¢„æµ‹ç½‘æ ¼ä¸­è¾¹çš„L2èŒƒæ•°ï¼Œä½¿ç½‘æ ¼æ›´å¹³æ»‘ã€‚

### å››ã€è®²å¸ˆæå‡ºçš„æ€è€ƒé¢˜ (Questions Posed by the Instructor)
-   å…³äº3Dè®¡ç®—æœºè§†è§‰çš„æ€»ä½“é—®é¢˜ (Any questions on the sort of preamble about 3D computer vision before we really really dive into these different types of models?) [04:30]
-   ä¸ºä»€ä¹ˆè¾“å…¥æ˜¯30 x 30 x 30ï¼Œç„¶ååªæœ‰1ä¸ªé€šé“ (Why does the input has a 30 x 30 x 30 and then only one channel?) [18:35]
-   å·ç§¯æ ¸æ˜¯å¦æ˜¯äºŒè¿›åˆ¶çš„ (Does the kernel that operates into this binary...?) [20:36]
-   å½“æˆ‘ä»¬ä»3Då·ç§¯æ¨¡å‹è½¬å‘ä½“ç´ ç®¡æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¼šç‰ºç‰²ä»€ä¹ˆ (what do we sort of sacrifice when we move from this 3D convolution model to this voxel tube representation model?) [26:26]
-   è¿™äº›ä¸åŒçš„æ–¹æ³•æ¸…æ™°å— (is is maybe this these these two different approaches of 3D convolution and voxel to representations clear for predicting voxel outputs?) [26:20]

---
1.ä»€ä¹ˆæ˜¯å›¾å·ç§¯