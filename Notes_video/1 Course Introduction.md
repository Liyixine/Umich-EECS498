### [📚] 视频学习脚手架: EECS 498-007 / 598-005 Deep Learning for Computer Vision - Lecture 1: Introduction

### 一、核心内容大纲 (Core Content Outline)
-   **课程介绍 (Course Introduction)**
    -   课程名称 (Course Name): EECS 498-007 / 598-005 深度学习用于计算机视觉 (Deep Learning for Computer Vision)
    -   本讲主题 (Lecture Topic): 介绍 (Introduction)
    -   课程性质 (Course Nature): 特殊专题课程，首次在密歇根大学开设 (Special topics class, first time taught at Michigan).
-   **计算机视觉 (Computer Vision) 定义与重要性**
    -   定义 (Definition): 构建能够处理 (process)、感知 (perceive) 和推理 (reason) 视觉数据 (visual data) 的人工智能系统 (artificial systems).
        -   “处理 (process)”、“感知 (perceive)”、“推理 (reason)”含义宽泛 (broad definitions).
        -   视觉数据示例 (Examples of visual data): 图像 (images)、视频 (videos)、医学扫描 (medical scans) 等任何连续值信号 (continuously valued signals).
    -   重要性 (Importance): 计算机视觉无处不在 (Computer Vision is everywhere).
        -   数据量巨大 (Massive amount of data):
            -   Instagram: 每天上传约 1 亿张照片和视频 (100 million photos/videos uploaded daily).
            -   YouTube (截至 2015 年): 每分钟上传约 300 小时视频 (300 hours of video uploaded every minute).
        -   人类无法处理如此海量数据 (Human manpower cannot process this data).
        -   未来重要性日益增加 (Increasing future importance): 自动驾驶汽车 (autonomous vehicles)、增强/虚拟现实 (augmented/virtual reality)、无人机 (drones) 等新兴技术 (emerging technologies).
    -   计算机视觉的核心问题 (Core Problem of Computer Vision): 理解视觉数据 (understanding visual data)，不关心如何实现 (doesn't care *how* it's solved).
-   **深度学习 (Deep Learning) 定义与定位**
    -   学习 (Learning) 的定义 (Definition of Learning): 构建能够从数据 (data) 和经验 (experience) 中学习的人工智能系统 (artificial systems that learn from data and experience).
    -   深度学习 (Deep Learning) 作为技术:
        -   目前计算机视觉领域主要使用深度学习 (Deep Learning is the prevailing technique in Computer Vision).
        -   深度学习是分层学习算法 (Hierarchical learning algorithms)，具有多层 (many "layers")，松散地受大脑启发 (loosely inspired by the brain)。但应谨慎看待与大脑的类比 (take brain comparisons with a grain of salt).
    -   **人工智能 (Artificial Intelligence)、机器学习 (Machine Learning)、计算机视觉 (Computer Vision) 和深度学习 (Deep Learning) 的关系 (Relationships)**:
        -   人工智能 (AI): 最广泛的领域 (broadest field)，目标是构建能够执行人类通常执行任务的智能机器 (build smart machines that do things normally done by people).
        -   机器学习 (ML): 人工智能的子领域 (sub-discipline of AI)，关注教机器学习 (teaching machines to learn).
        -   计算机视觉 (CV): 人工智能的子领域 (sub-discipline of AI)，关注教机器看 (teaching machines to see).
        -   深度学习 (DL): 机器学习的子集 (subset of Machine Learning)，与计算机视觉有重叠 (intersects with Computer Vision).
        -   本课程关注的焦点 (Focus of this class): 计算机视觉、机器学习和深度学习的交集 (intersection of Computer Vision, Machine Learning, and Deep Learning).
        -   AI 的其他子领域 (Other AI sub-areas): 自然语言处理 (Natural Language Processing)、语音识别 (Speech Recognition)、机器人学 (Robotics) 等。
-   **计算机视觉与深度学习简史 (Brief History of Computer Vision and Deep Learning)**
    -   **早期视觉研究 (Early Vision Research)**
        -   **Hubel 和 Wiesel, 1959** (Hubel and Wiesel, 1959):
            -   研究猫大脑的视觉皮层 (cat's visual cortex) 如何响应视觉刺激 (visual stimuli)。
            -   发现不同类型的神经元 (neurons) 对特定视觉模式 (visual patterns) 有响应。
                -   简单细胞 (Simple cells): 响应特定方向和位置的边缘 (oriented edges at specific orientation and position).
                -   复杂细胞 (Complex cells): 响应运动 (motion) 或任何位置的定向边缘 (oriented edges anywhere in visual field)，具有平移不变性 (translation invariance).
                -   超复杂细胞 (Hypercomplex cells): 响应带有端点的运动 (movement with an end point).
            -   影响 (Influence): 强调了面向边缘 (oriented edges) 和视觉系统的分层表示 (hierarchical representation) 的重要性。1981 年获诺贝尔奖 (Nobel Prize in 1981).
        -   **Larry Roberts, 1963** (Larry Roberts, 1963):
            -   可能最早的计算机视觉博士论文 (possibly the first PhD thesis on computer vision).
            -   系统能够从原始图像中检测边缘 (detect edges)，选择特征点 (select feature points)，并理解物体的三维几何形状 (understand 3D geometry of objects).
            -   挑战 (Challenge): 当时将图像信息输入计算机非常繁琐 (cumbersome to get photographic information into computers).
            -   Roberts 后来成为互联网的创始人 (later became the founding father of the Internet).
        -   **Seymour Papert, 1966** (Seymour Papert, 1966) – 暑期视觉项目 (The Summer Vision Project):
            -   MIT 的一个雄心勃勃的项目 (ambitious MIT project)，旨在暑期内构建“视觉系统的显著部分 (significant part of a visual system)”。
            -   目标未能实现 (goal not achieved)，表明计算机视觉的复杂性。
        -   **David Marr, 1970s** (David Marr, 1970s) – 视觉表征阶段 (Stages of Visual Representation):
            -   提出了视觉处理的四个阶段 (four stages of visual processing): 原始强度 (perceived intensities) -> 原始草图 (primal sketch) -> 2.5D 草图 (2 1/2-D sketch) -> 3D 模型表示 (3-D model representation)。
            -   再次强调了分层处理 (hierarchical processing)。
        -   **基于部分识别 (Recognition via Parts, 1970s)**:
            -   尝试将物体分解为基本几何部分进行识别。
            -   泛化圆柱体 (Generalized Cylinders, 1979) 和图像结构 (Pictorial Structures, 1973)。
            -   受限于当时计算能力和数字相机技术 (limited by computational power and digital camera technology).
        -   **基于边缘检测的识别 (Recognition via Edge Detection, 1980s)**:
            -   随着数字相机和计算能力的进步，研究更真实图像 (more realistic images)。
            -   John Canny, 1986: Canny 边缘检测器 (Canny Edge Detector)，一种鲁棒的边缘检测算法 (robust algorithm for detecting edges).
            -   David Lowe, 1987: 通过匹配边缘识别物体 (recognizing objects by matching their edges).
        -   **基于分组的识别 (Recognition via Grouping, 1990s)**:
            -   目标是将图像分割成语义上有意义的块 (segment image into semantically meaningful chunks)。
            -   归一化切割 (Normalized Cuts, Shi and Malik, 1997) 算法。
        -   **基于匹配的识别 (Recognition via Matching, 2000s)**:
            -   SIFT (Scale-Invariant Feature Transform) (David Lowe, 1999): 检测图像中的关键点 (keypoints)，并计算对尺度 (scale) 和旋转 (rotation) 不变的特征向量 (feature vectors) 来表示外观 (appearance)。
            -   用于在不同图像中匹配物体，即使有变换 (transformations)。
        -   **人脸检测 (Face Detection, 2000s)**:
            -   Viola and Jones, 2001: 提出了一种强大的人脸检测算法。
            -   里程碑 (Milestone): 机器学习在计算机视觉中的首批成功应用之一 (one of the first successful applications of Machine Learning to Vision)。
            -   快速商业化 (fast commercialization)，例如数码相机中的自动对焦 (auto-focus in digital cameras).
        -   **PASCAL 视觉物体挑战赛 (PASCAL Visual Object Challenge, 2000s)**:
            -   一个大规模的物体检测与识别基准挑战赛 (large-scale object detection and recognition benchmark challenge).
            -   推动了性能的稳步提升 (steady increase in performance).
        -   **ImageNet 大规模视觉识别挑战赛 (ImageNet Large Scale Visual Recognition Challenge, 2000s-2010s)**:
            -   一个包含 1000 个物体类别，140 多万张图像的巨型数据集 (massive dataset with over 1.4 million images and 1,000 object classes)。
            -   创新点 (Innovation): 利用众包 (crowdsourcing) 进行数据标注 (data annotation)。
            -   挑战赛每年举行，被称为“计算机视觉界的奥运会 (Olympics of Computer Vision)”。
            -   2010-2011年错误率在 25-28% 左右 (error rates around 25-28%).
            -   **2012 年：错误率显著下降到 16.4%** (error rate dropped to 16.4%)，这是“进入深度学习 (Enter Deep Learning)”的时刻。
            -   此后错误率持续快速下降，到 2017 年甚至低于人类的识别错误率 (performance surpassed human error rates).
    -   **深度学习历史 (History of Deep Learning)**
        -   **感知机 (Perceptron), ~1957** (Frank Rosenblatt):
            -   最早能够从数据中学习的算法之一 (one of the earliest algorithms that could learn from data)。
            -   硬件实现 (Implemented in hardware): 权重存储在电位器 (potentiometers) 中，学习时由电动机 (electric motors) 更新。
            -   能识别字母 (recognize letters of the alphabet) 的 20x20 像素图像。
            -   现代视角 (Modern perspective): 被认为是线性分类器 (linear classifier)。
        -   **Minsky 和 Papert, 1969** (Minsky and Papert, 1969):
            -   出版了名为《感知机》(Perceptrons) 的著作。
            -   指出感知机无法学习 XOR 函数 (XOR function) (非线性可分问题)。
            -   导致该领域大量幻灭 (caused a lot of disillusionment)，研究停滞，进入“AI 冬天 (AI Winter)”。
            -   **关键点 (Key Point)**：书中也提到了多层感知机 (multi-layer perceptrons) 可以解决此类问题，但当时被忽视。
        -   **新认知机 (Neocognitron): Fukushima, 1980** (Fukushima, 1980):
            -   计算模型 (computational model) 直接受到 Hubel 和 Wiesel 的启发，具有分层结构 (hierarchical structure) 的简单细胞 (simple cells) 和复杂细胞 (complex cells)。
            -   交错使用简单细胞 (卷积) (simple cells (convolution)) 和复杂细胞 (池化) (complex cells (pooling))。
            -   **问题 (Problem)**: 没有实用的训练算法 (no practical training algorithm)。
            -   整体架构与 32 年后的 AlexNet 非常相似 (overall architecture very similar to AlexNet more than 32 years later)。
        -   **反向传播 (Backprop): Rumelhart, Hinton, and Williams, 1986** (Rumelhart, Hinton, and Williams, 1986):
            -   引入反向传播算法 (backpropagation algorithm)，用于计算神经网络中的梯度 (gradients)。
            -   首次成功训练多层感知机 (successfully trained perceptrons with multiple layers)，解决了 Minsky 和 Papert 提出的问题。
            -   是深度学习能够有效训练的关键 (key for efficient training of deep neural networks).
            -   该算法使用了现代神经网络中常见的梯度 (gradients)、雅可比矩阵 (Jacobians) 和 Hessian 矩阵 (Hessians) 等数学术语 (mathematical terminology).
        -   **卷积神经网络 (Convolutional Networks): LeCun et al, 1998** (LeCun et al, 1998):
            -   将反向传播算法应用于类新认知机 (Neocognitron-like) 架构 (applied backprop algorithm to a Neocognitron-like architecture).
            -   成功识别手写数字 (learned to recognize handwritten digits) (LeNet 模型)。
            -   商业应用 (Commercial deployment): 被 NEC 公司用于处理手写支票 (processed handwritten checks)，一度处理了美国高达 10% 的支票 (up to 10% of all checks in the United States).
            -   与现代卷积神经网络非常相似 (very similar to modern convolutional networks).
        -   **2000s: “深度学习” (Deep Learning)**:
            -   人们尝试训练更深 (deeper) 的神经网络 (neural networks)。
            -   当时并非主流研究方向 (not a mainstream research topic at this time)。
            -   Hinton 和 Salakhutdinov (2006)、Bengio et al (2007)、Lee et al (2009)、Glorot 和 Bengio (2010) 等研究者推动了深度网络训练的发展。
            -   为 2012 年 AlexNet 的突破奠定了基础 (laid the groundwork for AlexNet's breakthrough).
-   **2012 年至今：深度学习大爆发 (Deep Learning Explosion)**
    -   **汇流 (Confluence)**: 2012 年是算法 (algorithms)、数据 (data) 和计算 (computation) 三大要素的汇流点 (great confluence of algorithms, data, and computation).
        -   **算法 (Algorithms)**: 经过多年发展，有了强大的可学习函数表示工具和反向传播等训练方法 (powerful tools for learnable functions and training methods).
        -   **数据 (Data)**: 数字相机、互联网和众包 (digital cameras, Internet, crowdsourcing) 带来海量标注数据 (unprecedented amounts of labeled data)，如 ImageNet。
        -   **计算 (Computation)**: GPU (Graphics Processing Units) 在性能与成本效益上爆发式增长 (exponential growth in GigaFLOPs per dollar for GPUs vs CPUs)，远超 CPU。例如，GeForce GTX 580 (AlexNet 使用) 和 GTX 1080 Ti。
    -   **影响 (Impact)**: 深度学习在 Google Trends 上的兴趣度以及在 CVPR (计算机视觉与模式识别会议) 上的论文提交和接受数量都呈指数级增长 (exponential growth in interest and publications).
    -   **应用无处不在 (ConvNets are everywhere)**:
        -   图像分类 (Image Classification): 为图像打标签 (putting labels on images).
        -   图像检索 (Image Retrieval): 从图像库中检索相似图像 (retrieving images from collections).
        -   物体检测 (Object Detection): 识别图像中物体的位置和类别 (recognizing positions and labels of objects).
        -   语义分割 (Image Segmentation - 视频中讲师口误说成 Image Retrieval): 像素级语义分组 (semantic grouping of pixels).
        -   视频分类 (Video Classification): 识别视频中的活动 (activity recognition).
        -   姿态识别 (Pose Recognition): 识别图像中人物的精确几何姿态 (estimating geometric poses of people).
        -   玩 Atari 游戏 (Playing Atari games): 处理视觉输入 (processing visual input) 并学习玩法 (learning how to play).
        -   医学影像 (Medical Imaging): 诊断肿瘤、皮肤病变等 (diagnosing tumors, skin lesions, etc.).
        -   星系分类 (Galaxy Classification).
        -   鲸鱼识别 (Whale recognition).
        -   图像描述 (Image Captioning) (利用 RNNs): 生成自然语言描述 (generating natural language descriptions).
        -   生成艺术 (Generating art): DeepDream、艺术风格迁移 (Artistic Style Transfer) 等 (DeepDream, Artistic Style Transfer).
    -   **计算机视觉的未来与挑战 (Future and Challenges of Computer Vision)**:
        -   尽管取得了巨大成功，计算机视觉仍有很长的路要走 (Despite our success, computer vision still has a long way to go).
        -   当前系统无法理解复杂场景中的物理和社会含义 (cannot understand physical and social implications in complex scenes), 例如奥巴马在体重秤上作弊的图片。
        -   未来潜力巨大 (Huge potential):
            -   使生活更有趣 (more fun): 游戏、AR/VR。
            -   交通更安全 (safer transportation): 自动驾驶。
            -   改善医疗诊断 (improved medical diagnosis).
            -   作为通用传感器 (universal sensor) 帮助科学家理解数据 (helping scientists understand data).
    -   **2018 年图灵奖 (2018 Turing Award)**: 授予 Yoshua Bengio, Geoffrey Hinton, 和 Yann LeCun，表彰他们在深度学习方面的开创性工作 (pioneering work in Deep Learning).

### 二、关键术语定义 (Key Term Definitions)
-   **简单细胞 (Simple cells)**: (Hubel and Wiesel) 猫视觉皮层中的神经元，响应特定方向和位置的边缘 (oriented edges at specific orientation and position).
-   **复杂细胞 (Complex cells)**: (Hubel and Wiesel) 猫视觉皮层中的神经元，响应运动或任何位置的定向边缘，具有平移不变性 (responds to motion or oriented edges anywhere, with translation invariance).
-   **感知机 (Perceptron)**: (Frank Rosenblatt) 最早能够从数据中学习的算法之一，硬件实现，被认为是线性分类器 (one of the earliest algorithms that could learn from data, hardware implementation, considered a linear classifier).
-   **多层感知机 (Multi-layer perceptron)**: 具有多个隐藏层 (multiple hidden layers) 的感知机，具有更强的函数表示能力 (more powerful function representation capabilities)。
-   **AI 冬天 (AI Winter)**: 1969 年 Minsky 和 Papert 出版《感知机》后，由于其局限性，导致对人工智能和神经网络研究的资助和兴趣锐减的时期 (a period of reduced funding and interest in AI and neural network research following the publication of "Perceptrons").
-   **新认知机 (Neocognitron)**: (Fukushima) 计算模型，直接受到 Hubel 和 Wiesel 启发，具有卷积 (convolution) 和池化 (pooling) 操作的交错层，但没有实用的训练算法 (computational model inspired by Hubel and Wiesel, with interleaved layers of convolution and pooling, but no practical training algorithm).
-   **反向传播 (Backpropagation)**: (Rumelhart, Hinton, and Williams) 用于计算神经网络中梯度的算法，使得有效训练多层神经网络成为可能 (algorithm for computing gradients in neural networks, enabling efficient training of multi-layer neural networks). 该算法使用了梯度 (gradients)、雅可比矩阵 (Jacobians) 和 Hessian 矩阵 (Hessians) 等数学术语 (mathematical terminology).
-   **卷积神经网络 (Convolutional Neural Network, CNN)**: (LeCun et al) 一种特殊类型的神经网络，擅长处理图像数据，通过卷积和池化操作进行特征学习 (a type of neural network specialized for image data, using convolution and pooling for feature learning).
-   **SIFT (Scale-Invariant Feature Transform)**: (David Lowe) 一种图像特征提取算法，能够检测图像中的关键点，并生成对尺度、旋转和光照变化具有不变性的特征描述符 (image feature extraction algorithm detecting keypoints and generating descriptors invariant to scale, rotation, and lighting).
-   **ImageNet**: (Fei-Fei Li et al) 一个大规模图像数据集 (large-scale image dataset)，用于视觉识别任务的基准测试 (benchmarking visual recognition tasks)。
-   **GPU (Graphics Processing Unit)**: 图形处理器，最初用于图形渲染，后因其并行计算能力在深度学习中发挥重要作用 (graphics processor, key for deep learning due to parallel computing).
-   **图灵奖 (Turing Award)**: 计算机科学领域的最高荣誉，被认为是“计算机科学的诺贝尔奖” (highest honor in computer science, considered the "Nobel Prize of computing").

### 三、核心算法与代码片段 (Core Algorithms & Code Snippets)
本次视频未包含详细的算法步骤或代码示例，主要侧重于概念介绍和历史沿革。视觉模型和算法通过图示和简介的方式呈现。

### 四、讲师提出的思考题 (Questions Posed by the Instructor)
-   “处理 (process)”、“感知 (perceive)”和“推理 (reason)”的含义是什么？ (What does process, perceive, and reason mean?) [0:44]
-   “视觉数据 (visual data)”意味着什么？ (What does visual data mean?) [0:48]
-   我们应该如何解决理解视觉数据的问题？(How do we solve the problem of understanding visual data?) [3:23]
-   什么是学习 (What is learning)? [3:42]
-   为什么计算机视觉和学习会结合在一起？(Why do Computer Vision and Learning go together?) [4:08]
-   为什么深度学习和大脑的比较应该被谨慎看待？(Why should comparisons between Deep Learning and the brain be taken with a grain of salt?) [5:01]
-   什么是人工智能？(What is Artificial Intelligence?) [5:31]
-   计算机视觉是否是唯一的人工智能类型？深度学习是否是唯一的人工智能类型？深度学习是否是唯一的计算机视觉类型？ (Is Computer Vision the only type of AI? Is Deep Learning the only type of AI? Is Deep Learning the only type of Computer Vision?) [6:30]
-   在潜入材料之前，关于历史性概述有什么问题吗？(Are there any questions about the historical overview before we dive into the material?) [30:00]
-   Minsky 和 Papert 的书出了什么问题？(What went wrong with Minsky and Papert's book?) [31:24]
-   是什么导致了 2012 年的深度学习大爆发？(What was it that happened in 2012 that made all of this take off?) [39:54]
-   尽管取得了成功，计算机视觉还有很长的路要走吗？(Despite our success, computer vision still has a long way to go?) [43:33]
-   关于内容或政策，有哪些问题？(Any questions about content, or policies, or late days, or anything like that?) [50:56]
-   这个课程的材料是否可以供不在等待名单上的人使用？(Will the course materials be available for people not on the waitlist?) [51:00]
-   在第一个作业中可以使用任意数量的延迟天数吗？(Can we use as many late days as we want for the first assignment?) [51:16]
-   关于合作政策有任何问题吗？(Any questions about the collaboration policy?) [52:41]